{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b875b31c",
   "metadata": {},
   "source": [
    "# OpenVINO API Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abd9f4",
   "metadata": {},
   "source": [
    "This notebook explains the basics of the OpenVINO Inference Engine API. It covers:\n",
    "\n",
    "- [Load Inference Engine and Show Info](#Load-Inference-Engine-and-Show-Info)\n",
    "- [Loading a Model](#Loading-a-Model)\n",
    "  - [IR Model](#IR-Model)\n",
    "  - [ONNX Model](#ONNX-Model)\n",
    "- [Getting Information about a Model](#Getting-Information-about-a-Model)\n",
    "  - [Model Inputs](#Model-Inputs)\n",
    "  - [Model Outputs](#Model-Outputs)\n",
    "- [Doing Inference on a Model](#Doing-Inference-on-a-Model)\n",
    "- [Reshaping and Resizing](#Reshaping-and-Resizing)\n",
    "  - [Change Image Size](#Change-Image-Size)\n",
    "  - [Change Batch Size](#Change-Batch-Size)\n",
    " - [Caching a Model](#Caching-a-Model)\n",
    "    \n",
    "The notebook is divided into sections with headers. Each section is standalone and does not depend on previous sections. A segmentation and classification IR model and a segmentation ONNX model are provided as examples. You can replace these model files with your own models. The exact outputs will be different, but the process is the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed058f4",
   "metadata": {},
   "source": [
    "## Load Inference Engine and Show Info\n",
    "\n",
    "Initialize Inference Engine with Core()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08b79c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intel/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/intel/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "ie = Core()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc4125",
   "metadata": {},
   "source": [
    "Inference Engine can load a network on a device. A device in this context means a CPU, an Intel GPU, a Neural Compute Stick 2, etc. The `available_devices` property shows the devices that are available on your system. The \"FULL_DEVICE_NAME\" option to `ie.get_property()` shows the name of the device.\n",
    "\n",
    "In this notebook the CPU device is used. To use an integrated GPU, use `device_name=\"GPU\"` instead. Note that loading a network on GPU will be slower than loading a network on CPU, but inference will likely be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c94f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 11th Gen Intel(R) Core(TM) i9-11900K @ 3.50GHz\n"
     ]
    }
   ],
   "source": [
    "devices = ie.available_devices\n",
    "\n",
    "for device in devices:\n",
    "    device_name = ie.get_property(device_name=device, name=\"FULL_DEVICE_NAME\")\n",
    "    print(f\"{device}: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d62615",
   "metadata": {},
   "source": [
    "## Loading a Model\n",
    "\n",
    "After initializing Inference Engine, first read the model file with `read_model()`, then compile it to the specified device with `compile_model()`. \n",
    "\n",
    "### IR Model\n",
    "\n",
    "An IR (Intermediate Representation) model consists of an .xml file, containing information about network topology, and a .bin file, containing the weights and biases binary data. `read_model()` expects the weights file to be located in the same directory as the xml file, with the same filename, and the extension .bin: `model_weights_file == Path(model_xml).with_suffix(\".bin\")`. If this is the case, specifying the weights file is optional. If the weights file has a different filename, it can be specified with the `weights` parameter to `read_model()`.\n",
    "\n",
    "See the [tensorflow-to-openvino](../101-tensorflow-to-openvino/101-tensorflow-to-openvino.ipynb) and [pytorch-onnx-to-openvino](../102-pytorch-onnx-to-openvino/102-pytorch-onnx-to-openvino.ipynb) notebooks for information on how to convert your existing TensorFlow, PyTorch or ONNX model to OpenVINO's IR format with OpenVINO's Model Optimizer. For exporting ONNX models to IR with default settings, the `.serialize()` method can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "523978fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "ie = Core()\n",
    "classification_model_xml = \"model/classification.xml\"\n",
    "\n",
    "model = ie.read_model(model=classification_model_xml)\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5516e87",
   "metadata": {},
   "source": [
    "### ONNX Model\n",
    "\n",
    "An ONNX model is a single file. Reading and loading an ONNX model works the same way as reading and loading an IR model. The `model` argument points to the ONNX filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15833f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "ie = Core()\n",
    "onnx_model_path = \"model/segmentation.onnx\"\n",
    "model_onnx = ie.read_model(model=onnx_model_path)\n",
    "compiled_model_onnx = ie.compile_model(model=model_onnx, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4a187",
   "metadata": {},
   "source": [
    "The ONNX model can be exported to IR with .serialize():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fb397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.offline_transformations import serialize\n",
    "\n",
    "serialize(model=model_onnx, model_path=\"model/exported_onnx_model.xml\", weights_path=\"model/exported_onnx_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebee450",
   "metadata": {},
   "source": [
    "## Getting Information about a Model\n",
    "\n",
    "The OpenVINO IENetwork instance stores information about the model. Information about the inputs and outputs of the model are in `model.inputs` and `model.outputs`. These are also properties of the ExecutableNetwork instance. Where we use `model.inputs` and `model.outputs` in the cells below, you can also use `compiled_model.inputs` and `compiled_model.outputs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc79b32",
   "metadata": {},
   "source": [
    "### Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5571614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "ie = Core()\n",
    "classification_model_xml = \"model/classification.xml\"\n",
    "model = ie.read_model(model=classification_model_xml)\n",
    "model.input(0).any_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb1299",
   "metadata": {},
   "source": [
    "The cell above shows that the model loaded expects one input, with the name _input_. If you loaded a different model, you may see a different input layer name, and you may see more inputs.\n",
    "\n",
    "It is often useful to have a reference to the name of the first input layer. For a model with one input, `model.input(0)` gets this name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf48354",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = model.input(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea90446",
   "metadata": {},
   "source": [
    "Information for this input layer is stored in `inputs`. The next cell prints the input layout, precision and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0bc0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input precision: <Type: 'float32'>\n",
      "input shape: {1, 3, 224, 224}\n"
     ]
    }
   ],
   "source": [
    "print(f\"input precision: {input_layer.element_type}\")\n",
    "print(f\"input shape: {input_layer.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189a73c",
   "metadata": {},
   "source": [
    "This cell output tells us that the model expects inputs with a shape of [1,3,224,224], and that this is in NCHW layout. This means that the model expects input data with a batch size (N) of 1, 3 channels (C), and images of a height (H) and width (W) of 224. The input data is expected to be of FP32 (floating point) precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155cf48e",
   "metadata": {},
   "source": [
    "### Model Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4583eb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MobilenetV3/Predictions/Softmax'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "ie = Core()\n",
    "classification_model_xml = \"model/classification.xml\"\n",
    "model = ie.read_model(model=classification_model_xml)\n",
    "model.output(0).any_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189c02f",
   "metadata": {},
   "source": [
    "Model output info is stored in `model.outputs`. The cell above shows that the model returns one output, with the name _MobilenetV3/Predictions/Softmax_. If you loaded a different model, you will probably see a different output layer name, and you may see more outputs.\n",
    "\n",
    "Since this model has one output, follow the same method as for the input layer to get its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88fbbd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Output: names[MobilenetV3/Predictions/Softmax] shape{1,1001} type: f32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer = model.output(0)\n",
    "output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad0240",
   "metadata": {},
   "source": [
    "Getting the output precision and shape is similar to getting the input precision and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee5e14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output precision: <Type: 'float32'>\n",
      "output shape: {1, 1001}\n"
     ]
    }
   ],
   "source": [
    "print(f\"output precision: {output_layer.element_type}\")\n",
    "print(f\"output shape: {output_layer.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739f5bb",
   "metadata": {},
   "source": [
    "This cell output shows that the model returns outputs with a shape of [1, 1001], where 1 is the batch size (N) and 1001 the number of classes (C). The output is returned as 32-bit floating point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021708ab",
   "metadata": {},
   "source": [
    "## Doing Inference on a Model\n",
    "\n",
    "To do inference on a model, first you need to create inference request by calling `create_infer_request()` being method of _ExecutableNetwork_, the `exec_net` that we loaded with `compile_model()`. Than you have to call `infer()`, being the method of `_InferRequest_`, expects one argument: _inputs_. This is a dictionary, mapping input layer names to input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2eac8",
   "metadata": {},
   "source": [
    "**Preparation: load network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "298c80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "ie = Core()\n",
    "classification_model_xml = \"model/classification.xml\"\n",
    "model = ie.read_model(model=classification_model_xml)\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173cd1c9",
   "metadata": {},
   "source": [
    "**Preparation: load image and convert to input shape**\n",
    "\n",
    "To propagate an image through the network, it needs to be loaded into an array, resized to the shape that the network expects, and converted to the network's input layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f23c43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(663, 994, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image_filename = \"data/coco_hollywood.jpg\"\n",
    "image = cv2.imread(image_filename)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf541d8",
   "metadata": {},
   "source": [
    "The image has a shape of (663,994,3). It is 663 pixels in height, 994 pixels in width, and has 3 color channels. We get a reference to the height and width that the network expects and resize the image to that size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f97da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N,C,H,W = batch size, number of channels, height, width\n",
    "N, C, H, W = input_layer.shape\n",
    "# OpenCV resize expects the destination size as (width, height)\n",
    "resized_image = cv2.resize(src=image, dsize=(W, H))\n",
    "resized_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a6d74",
   "metadata": {},
   "source": [
    "Now the image has the width and height that the network expects. It is still in H,W,C format. We change it to N,C,H,W format (where N=1) by first calling `np.transpose()` to change to C,H,W and then adding the N dimension by calling `np.expand_dims()`. Convert the data to FP32 with `np.astype()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d09b7275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_data = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0).astype(np.float32)\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af110efb",
   "metadata": {},
   "source": [
    "**Do inference**\n",
    "\n",
    "Now that the input data is in the right shape, do the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "098c8cb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = compiled_model([input_data])[output_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a131e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also create `InferRequest` and run `infer` method on request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf94022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = compiled_model.create_infer_request()\n",
    "request.infer(inputs={input_layer.any_name: input_data})\n",
    "result = request.get_output_tensor(output_layer.index).data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf7c61",
   "metadata": {},
   "source": [
    "`.infer()` sets output tensor, that we can reach using `get_output_tensor()`. Since we know this network returns one output, and we stored the reference to the output layer in the `output_layer.index` parameter, we can get the data with `request.get_output_tensor(output_layer.index)`. To get numpy array from output we need to take parameter `.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a0f63b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5834ee",
   "metadata": {},
   "source": [
    "The output shape is (1,1001), which we saw is the expected shape of the output. This output shape indicates that the network returns probabilities for 1001 classes. To transform this into meaningful information, check out the [hello world notebook](../001-hello-world/001-hello-world.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a9be1",
   "metadata": {},
   "source": [
    "## Reshaping and Resizing\n",
    "\n",
    "### Change Image Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239b10c",
   "metadata": {},
   "source": [
    "Instead of reshaping the image to fit the model, you can also reshape the model to fit the image. Note that not all models support reshaping, and models that do may not support all input shapes. The model accuracy may also suffer if you reshape the model input shape.\n",
    "\n",
    "We first check the input shape of the model, and then reshape to the new input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc1a69f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ ORIGINAL MODEL ~~~~\n",
      "input shape: {1, 3, 512, 512}\n",
      "output shape: {1, 1, 512, 512}\n",
      "~~~~ RESHAPED MODEL ~~~~\n",
      "model input shape: {1, 3, 544, 544}\n",
      "compiled_model input shape: {1, 3, 544, 544}\n",
      "compiled_model output shape: {1, 1, 544, 544}\n"
     ]
    }
   ],
   "source": [
    "from openvino.runtime import Core, PartialShape\n",
    "\n",
    "ie = Core()\n",
    "segmentation_model_xml = \"model/segmentation.xml\"\n",
    "segmentation_model = ie.read_model(model=segmentation_model_xml)\n",
    "segmentation_input_layer = segmentation_model.input(0)\n",
    "segmentation_output_layer = segmentation_model.output(0)\n",
    "\n",
    "print(\"~~~~ ORIGINAL MODEL ~~~~\")\n",
    "print(f\"input shape: {segmentation_input_layer.shape}\")\n",
    "print(f\"output shape: {segmentation_output_layer.shape}\")\n",
    "\n",
    "new_shape = PartialShape([1, 3, 544, 544])\n",
    "segmentation_model.reshape({segmentation_input_layer.any_name: new_shape})\n",
    "segmentation_compiled_model = ie.compile_model(model=segmentation_model, device_name=\"CPU\")\n",
    "# help(segmentation_compiled_model)\n",
    "print(\"~~~~ RESHAPED MODEL ~~~~\")\n",
    "print(f\"model input shape: {segmentation_input_layer.shape}\")\n",
    "print(\n",
    "    f\"compiled_model input shape: \"\n",
    "    f\"{segmentation_compiled_model.input(index=0).shape}\"\n",
    ")\n",
    "print(f\"compiled_model output shape: {segmentation_output_layer.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104cef6",
   "metadata": {},
   "source": [
    "The input shape for the segmentation network is [1,3,512,512], with an NCHW layout: the network expects 3-channel images with a width and height of 512 and a batch size of 1. We reshape the network to make it accept input images with a width and height of 544 with the `.reshape()` method of `IENetwork`. This segmentation network always returns arrays with the same width and height as the input width and height, so setting the input dimensions to 544x544 also modifies the output dimensions. After reshaping, compile the network once again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249d697a",
   "metadata": {},
   "source": [
    "### Change Batch Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded79c8f",
   "metadata": {},
   "source": [
    "We can also use `.reshape()` to set the batch size, by increasing the first element of _new_shape_. For example, to set a batch size of two, set `new_shape = (2,3,544,544)` in the cell above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a49d65c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: {2, 3, 544, 544}\n",
      "output shape: {2, 1, 544, 544}\n"
     ]
    }
   ],
   "source": [
    "from openvino.runtime import Core, PartialShape\n",
    "\n",
    "ie = Core()\n",
    "segmentation_model_xml = \"model/segmentation.xml\"\n",
    "segmentation_model = ie.read_model(model=segmentation_model_xml)\n",
    "segmentation_input_layer = segmentation_model.input(0)\n",
    "segmentation_output_layer = segmentation_model.output(0)\n",
    "new_shape = PartialShape([2, 3, 544, 544])\n",
    "segmentation_model.reshape({segmentation_input_layer.any_name: new_shape})\n",
    "segmentation_compiled_model = ie.compile_model(model=segmentation_model, device_name=\"CPU\")\n",
    "\n",
    "print(f\"input shape: {segmentation_input_layer.shape}\")\n",
    "print(f\"output shape: {segmentation_output_layer.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c2f3d2",
   "metadata": {},
   "source": [
    "The output shows that by setting the batch size to 2, the first element (N) of the input and output shape now has a value of 2. Let's see what happens if we propagate our input image through the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eb487fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape: (2, 3, 544, 544)\n",
      "result data data shape: {2, 1, 544, 544}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from openvino.runtime import Core, PartialShape\n",
    "\n",
    "ie = Core()\n",
    "segmentation_model_xml = \"model/segmentation.xml\"\n",
    "segmentation_model = ie.read_model(model=segmentation_model_xml)\n",
    "segmentation_input_layer = segmentation_model.input(0)\n",
    "segmentation_output_layer = segmentation_model.output(0)\n",
    "new_shape = PartialShape([2, 3, 544, 544])\n",
    "segmentation_model.reshape({segmentation_input_layer.any_name: new_shape})\n",
    "segmentation_compiled_model = ie.compile_model(model=segmentation_model, device_name=\"CPU\")\n",
    "input_data = np.random.rand(2, 3, 544, 544)\n",
    "\n",
    "output = segmentation_compiled_model([input_data])\n",
    "\n",
    "print(f\"input data shape: {input_data.shape}\")\n",
    "print(f\"result data data shape: {segmentation_output_layer.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578260a-d202-4fe7-8618-307f034ea7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae617ccb002f72b3ab6d0069d721eac67ac2a969e83c083c4321cfcab0437cd1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
