{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Object Detection Sample Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "This sample requires the following:\n",
    "- All files are present and in the following directory structure:\n",
    "    - **object_detection.ipynb** - This Jupyter* Notebook\n",
    "    - **object_detection.py** - Python* code for object detection application\n",
    "    - **object_detection_annotate.py** - Python* code to perform post-processing to annotate output video\n",
    "    - **labels.txt** - Mapping of numerical labels to text strings\n",
    "    - **/data/reference-sample-data/object-detection-python/cars_1900.mp4** - Test video\n",
    "\n",
    "It is recommended that you have already read the following from [Get Started on the Intel® DevCloud for the Edge](https://devcloud.intel.com/edge/home/):\n",
    "- [Overview of the Intel® DevCloud for the Edge](https://devcloud.intel.com/edge/get_started/devcloud/)\n",
    "- [Overview of the Intel® Distribution of OpenVINO™ toolkit](https://devcloud.intel.com/edge/get_started/openvino/)\n",
    "\n",
    "<br><div class=note><i><b>Note: </b>It is assumed that the server this sample is being run on is on the Intel® DevCloud for the Edge which has Jupyter* Notebook customizations and all the required libraries already installed.  If you download or copy to a new server, this sample may not run.</i></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This sample application demonstrates how a smart video IoT solution may be created using Intel® hardware and software tools to perform object detection.  This solution detects any number of objects within a video frame looking specifically for known objects. \n",
    "\n",
    "The results for each frame are stored in a text file that is later read by a second pass to annotate the input video with boxes around detected objects with a label and probability value.\n",
    "\n",
    "### Key concepts\n",
    "This sample application includes an example for the following:\n",
    "- Application:\n",
    "  - Video and image input is supported using OpenCV\n",
    "  - OpenCV is used to draw bounding boxes around detected objects, labels, and other information\n",
    "  - Visualization of the resulting bounding boxes in the output\n",
    "  - Uses the [Async API](https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Intro_to_Performance.html) feature of the Inference Engine\n",
    "- Intel® DevCloud for the Edge:\n",
    "  - Submitting inference as jobs that are performed on different edge compute nodes (rather than on the development node hosting this Jupyter* notebook)\n",
    "  - Monitoring job status\n",
    "  - Viewing results and assessing performance for hardware on different compute nodes\n",
    "- [Intel® Distribution of OpenVINO™ toolkit](https://software.intel.com/openvino-toolkit):\n",
    "  - Create the necessary Intermediate Representation (IR) files for the inference model using the [Model Downloader](http://docs.openvinotoolkit.org/latest/_tools_downloader_README.html) and [Model Optimizer](http://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html)\n",
    "  - Run an inference application on multiple hardware devices using the [Inference Engine](http://docs.openvinotoolkit.org/latest/_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async API feature\n",
    "\n",
    "Inference may be run in the Inference Engine using either the synchronous (blocking) or asynchronous (non-blocking) API of the [ExectuableNetwork](https://docs.openvinotoolkit.org/latest/ie_python_api/classie__api_1_1ExecutableNetwork.html) and [InferRequest](https://docs.openvinotoolkit.org/latest/ie_python_api/classie__api_1_1InferRequest.html) classes:\n",
    "- Synchronous API:\n",
    "```python\n",
    "   # Runs inference and returns results when complete\n",
    "   result = exec_net.infer(inputs) \n",
    "```\n",
    "\n",
    "- Asynchronous API\n",
    "```python\n",
    "   # Start inference and return immediately with an InferenceRequest (optional to use)\n",
    "   infer_request = exec_net.start_async(request_id, inputs)\n",
    "\n",
    "   # ... Perform other work such as capturing input data, preprocessing input data,\n",
    "   #     post-processing results, etc. ...\n",
    "\n",
    "   # Check the status of inference one of two ways, both use timeout set to:\n",
    "   #    ms_timeout = 0      - Return status immediately whether inference is complete or not\n",
    "   #    ms_timeout = -1     - Wait until inference is complete, then return\n",
    "   #    ms_timeout = <time> - Wait time in milliseconds or until inference complete\n",
    "\n",
    "   # Option #1: Use the returned InferenceRequest\n",
    "   infer_status = infer_request.wait(ms_timeout)\n",
    "\n",
    "   # Option #2: Lookup InferenceRequest using the request_id used with start_async()\n",
    "   infer_status = exec_net.requests[my_request_id].wait(ms_timeout)\n",
    "```\n",
    "\n",
    "<br><div class=note><i><b>Note: </b>Using `infer()` is effectively the same as calling `start_async()` immediately followed by waiting for the results.</i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Async API](https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Intro_to_Performance.html) feature is used to run inference in parallel on either a separate thread or device allowing the main thread to continue to do other work such as capturing input data, preprocessing input data, post-processing results, etc.  In this sample application, the Async API is used to perform inference in parallel with loading the next video frame and post-processing inference results. \n",
    "Below is an outline of the code for the main loop appearing in [object_detection.py](./object_detection.py):\n",
    "\n",
    "```python\n",
    "current_inference = 0\n",
    "previous_inference = 1 - args.number_infer_requests\n",
    "infer_requests = exec_net.requests\n",
    "frame_count = 0\n",
    "\n",
    "while frame_count < video_len:\n",
    "    # Read next frame from input stream if available and submit it for inference \n",
    "    # ...\n",
    "        exec_net.start_async(request_id=current_inference, inputs={input_blob: in_frame})\n",
    "\n",
    "    # Retrieve the output of an earlier inference request\n",
    "    if previous_inference >= 0:\n",
    "        status = infer_requests[previous_inference].wait()\n",
    "        # ... post-processing current frame ...\n",
    "        frame_count += 1\n",
    "\n",
    "    # Increment counter for the inference queue and roll them over if necessary \n",
    "    current_inference += 1\n",
    "    if current_inference >= args.number_infer_requests:\n",
    "        current_inference = 0\n",
    "\n",
    "    previous_inference += 1\n",
    "    if previous_inference >= args.number_infer_requests:\n",
    "        previous_inference = 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection application\n",
    "The object detection application uses the Intel® Distribution of OpenVINO™ toolkit to perform inference on an input video to locate known objects within each frame.  We will setup, run, and view the results for this application for several different hardware devices (CPU. GPU, etc.) available on the compute nodes within the Intel® DevCloud for the Edge.  To accomplish this, we will be performing the following tasks:\n",
    "\n",
    "1. Use the [Model Downloader](http://docs.openvinotoolkit.org/latest/_tools_downloader_README.html) to download the inference model IR files needed to perform inference\n",
    "2. Use the [Model Optimizer](http://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html) to create the model IR files in the necessary precisions\n",
    "3. Create the job file used to submit running inference on compute nodes\n",
    "4. Submit jobs for different compute nodes and monitor the job status until complete\n",
    "5. View results and assess performance \n",
    "\n",
    "### How it works\n",
    "At startup the object detection application configures itself by parsing the command line arguments and reading the specified labels file.  Once configured, the application loads the specified inference model's IR files into the [Inference Engine](http://docs.openvinotoolkit.org/latest/_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html) and runs the three phases described in the following sections.\n",
    "#### Phase 1:  Pre-processing\n",
    "The frames from the specified input video are read and pre-processed to have the frame data ready for input into inference.  Each frame is resized and its channels are transposed to match the input of the input requirements of the inference model.  The resulting blocks of frame data are written to the binary file `tmp/processed_vid.bin`.\n",
    "\n",
    "#### Phase 2:  Inference\n",
    "The binary file `tmp/processed_vid.bin` is read for input to inference to detect known objects.  For each detected object within a frame, a message is written as a line to the output text file in the form:\n",
    "```\n",
    "   <frame_id> <xmin> <ymin> <xmax> <ymax> <class_id> <det_label> <det_time>\n",
    "```\n",
    "Where each field reports:\n",
    "- <*frame_id*> - Frame number of results\n",
    "- <*xmin*> - Minimum x coordinate for restriction zone\n",
    "- <*ymin*> - Minimum y coordinate for restriction zone\n",
    "- <*xmax*> - Maximum x coordinate for restriction zone\n",
    "- <*ymax*> - Maximum y coordinate for restriction zone\n",
    "- <*class_id*> - The class identifier (integer) from the inference results \n",
    "- <*det_label*> - Detection label: \"True\" if safe, \"False\" if unsafe\n",
    "- <*det_time*> - Detection time taken to perform inference (\"N/A\" due to using Async API)\n",
    "\n",
    "#### Phase 3:  Post-processing\n",
    "After the object detection application has finished running inference, a second executable is run to annotate the input video with the results from the output text file.  The final results is an output video with boxes drawn around detected objects with each box appearing with a label and probability value.\n",
    "\n",
    "In this sample, we provide three performance numbers for each architecture. However, they are not hard limits on the solution's performance. It is important to understand that for any application, you may want to combine preprocessing, inference, and post-processing, as opposed to separating them as done here. Combined preprocessing has several advantages:\n",
    "- If inference is run asynchronously on the accelerator, the rest of the system is available for parallel tasks for capturing input, preprocessing future frames, or post-processing past frames.\n",
    "- The inference application pipeline has better data locality, allowing for the reuse of data in caches such as in the application's memory or in the hard drive's cache. \n",
    "\n",
    "To run the application on the Intel® DevCloud for the Edge, a job is submitted to an edge compute node with a hardware accelerator such as Intel® HD Graphics GPU and Intel® Movidius™ Neural Compute Stick 2.  After inference on the input is completed, the output is stored in the appropriate `results/<architecture>/` directory.  The results are then viewed within this Jupyter* Notebook using the `videoHTML` video playback utility.\n",
    "\n",
    "The application and inference code for this sample is already implemented in the Python* files: \n",
    "- First pass, detection using inference: [`object_detection.py`](./object_detection.py)\n",
    "- Second pass, annotation using detection results: [`object_detection_annotate.py`](./object_detection_annotate.py)\n",
    "\n",
    "The following sections will guide you through configuring and running the object detection application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "The following sections describe all the necessary configuration to run the object detection application.\n",
    "#### Command line arguments\n",
    "The application is run from the command line using the following format:\n",
    "```bash\n",
    "python3 object_detection.py <arguments...>\n",
    "```\n",
    "The required command line _<arguments...>_ to run the Python* executable [`object_detection.py`](./object_detection.py) are:\n",
    "- **-m** - Path to the _.xml_ IR file (created using [Model Optimizer](http://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html)) for the inference model. \n",
    "- **-i** - Path to input video file\n",
    "- **--labels** - Path to labels file that matches the trained model used\n",
    "- **-o** - The path to where the output video file will be stored\n",
    "- **-d** - Device type to use to run inference (CPU, GPU, MYRIAD)\n",
    "- **-nreq** - The maximum number of requests to allow while using the Async API\n",
    "\n",
    "The second pass of the application to annotate video with results is run from the command line using the following format:\n",
    "```bash\n",
    "python3 object_detection_annotate.py <arguments...>\n",
    "```\n",
    "The required command line _<arguments...>_ to run the application Python* executable [`object_detection_annotate.py`](./object_detection_annotate.py) are:\n",
    "- **-i** - Path to input video file\n",
    "- **-o** - The path to where the output video file will be stored.  Also used with environment variable `PBS_JOBID` to find output text file from application executable\n",
    "- **-f** - Output frame rate scale value (FPS=50.0/<*val*>)\n",
    "- **-s** - Output resolution scale value to (input_w*<*val*>,input_h*<*val*>) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The labels file\n",
    "\n",
    "In order to label detected objects, the sample application requires a labels file associated with the model being used for detection.  The labels file is a text file containing all the classes/labels that the model can recognize, in the order that it was trained to recognize them (one class per line).  The included labels file `labels.txt`, is intended to be used with the specific `mobilenet-ssd` model that will be used for inference.\n",
    "\n",
    "Below are the contents of the `labels.txt` file that we will be using:\n",
    "```\n",
    "background\n",
    "aeroplane\n",
    "bicycle\n",
    "bird\n",
    "boat\n",
    "bottle\n",
    "bus\n",
    "car\n",
    "cat\n",
    "chair\n",
    "cow\n",
    "diningtable\n",
    "dog\n",
    "horse\n",
    "motorbike\n",
    "person\n",
    "pottedplant\n",
    "sheep\n",
    "sofa\n",
    "train\n",
    "tvmonitor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "We begin by importing all the Python* modules that will be used within this Jupyter* Notebook to run and display the results of the object detection application on the Intel® DevCloud for the Edge:\n",
    "- [os](https://docs.python.org/3/library/os.html#module-os) - Operating system specific module (used for file name parsing)\n",
    "- [time](https://docs.python.org/3/library/time.html#module-time) - Time tracking module (used for measuring execution time)\n",
    "- [matplotlib.pyplot](https://matplotlib.org/) - pyplot is used for displaying output images\n",
    "- [sys](https://docs.python.org/3/library/sys.html#module-sys) - System specific parameters and functions\n",
    "- [qarpo.demoutils](https://github.com/ColfaxResearch/qarpo) - Provides utilities for displaying results and managing jobs from within this Jupyter* Notebook\n",
    "\n",
    "Run the following cell to import the Python* dependencies needed.\n",
    "\n",
    "<br><div class=tip><b>Tip: </b>Select a cell and then use **Ctrl+Enter** to run that cell.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Python modules successfully.\n",
      "/data/venv/openvino_2022.1.0.643\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from qarpo.demoutils import *\n",
    "from qarpo.model_visualizer_link import *\n",
    "print('Imported Python modules successfully.')\n",
    "!echo $VENV_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the IR files for the inference model\n",
    "\n",
    "The Intel® Distribution of OpenVINO™ toolkit includes the [Model Optimizer](http://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html) used to convert and optimize trained models into the Intermediate Representation (IR) model files, and the [Inference Engine](http://docs.openvinotoolkit.org/latest/_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html) that uses the IR model files to run inference on hardware devices.  The IR model files can be created from trained models from popular frameworks (e.g. Caffe\\*, Tensorflow*, etc.). \n",
    "The Intel® Distribution of OpenVINO™ toolkit also includes the [Model Downloader](http://docs.openvinotoolkit.org/latest/_tools_downloader_README.html) utility  to download some common inference models from the [Open Model Zoo](https://github.com/opencv/open_model_zoo). \n",
    "\n",
    "Run the following cell to run the Model Downloader utility with the `--print_all` argument to see all the available inference models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphereface\n",
      "aclnet\n",
      "aclnet-int8\n",
      "action-recognition-0001\n",
      "age-gender-recognition-retail-0013\n",
      "alexnet\n",
      "anti-spoof-mn3\n",
      "asl-recognition-0004\n",
      "background-matting-mobilenetv2\n",
      "bert-base-ner\n",
      "bert-large-uncased-whole-word-masking-squad-0001\n",
      "bert-large-uncased-whole-word-masking-squad-emb-0001\n",
      "bert-large-uncased-whole-word-masking-squad-int8-0001\n",
      "bert-small-uncased-whole-word-masking-squad-0001\n",
      "bert-small-uncased-whole-word-masking-squad-0002\n",
      "bert-small-uncased-whole-word-masking-squad-emb-int8-0001\n",
      "bert-small-uncased-whole-word-masking-squad-int8-0002\n",
      "brain-tumor-segmentation-0001\n",
      "brain-tumor-segmentation-0002\n",
      "caffenet\n",
      "cocosnet\n",
      "colorization-siggraph\n",
      "colorization-v2\n",
      "common-sign-language-0001\n",
      "common-sign-language-0002\n",
      "ctdet_coco_dlav0_512\n",
      "ctpn\n",
      "deblurgan-v2\n",
      "deeplabv3\n",
      "densenet-121\n",
      "densenet-121-tf\n",
      "detr-resnet50\n",
      "dla-34\n",
      "driver-action-recognition-adas-0002\n",
      "drn-d-38\n",
      "efficientdet-d0-tf\n",
      "efficientdet-d1-tf\n",
      "efficientnet-b0\n",
      "efficientnet-b0-pytorch\n",
      "efficientnet-v2-b0\n",
      "efficientnet-v2-s\n",
      "emotions-recognition-retail-0003\n",
      "f3net\n",
      "face-detection-0200\n",
      "face-detection-0202\n",
      "face-detection-0204\n",
      "face-detection-0205\n",
      "face-detection-0206\n",
      "face-detection-adas-0001\n",
      "face-detection-retail-0004\n",
      "face-detection-retail-0005\n",
      "face-detection-retail-0044\n",
      "face-recognition-resnet100-arcface-onnx\n",
      "face-reidentification-retail-0095\n",
      "faceboxes-pytorch\n",
      "facenet-20180408-102900\n",
      "facial-landmarks-35-adas-0002\n",
      "facial-landmarks-98-detection-0001\n",
      "fast-neural-style-mosaic-onnx\n",
      "faster-rcnn-resnet101-coco-sparse-60-0001\n",
      "faster_rcnn_inception_resnet_v2_atrous_coco\n",
      "faster_rcnn_resnet50_coco\n",
      "fastseg-large\n",
      "fastseg-small\n",
      "fbcnn\n",
      "fcrn-dp-nyu-depth-v2-tf\n",
      "formula-recognition-medium-scan-0001\n",
      "formula-recognition-polynomials-handwritten-0001\n",
      "forward-tacotron\n",
      "gaze-estimation-adas-0002\n",
      "gmcnn-places2-tf\n",
      "googlenet-v1\n",
      "googlenet-v1-tf\n",
      "googlenet-v2\n",
      "googlenet-v2-tf\n",
      "googlenet-v3\n",
      "googlenet-v3-pytorch\n",
      "googlenet-v4-tf\n",
      "gpt-2\n",
      "handwritten-english-recognition-0001\n",
      "handwritten-japanese-recognition-0001\n",
      "handwritten-score-recognition-0003\n",
      "handwritten-simplified-chinese-recognition-0001\n",
      "hbonet-0.25\n",
      "hbonet-1.0\n",
      "head-pose-estimation-adas-0001\n",
      "higher-hrnet-w32-human-pose-estimation\n",
      "horizontal-text-detection-0001\n",
      "hrnet-v2-c1-segmentation\n",
      "human-pose-estimation-0001\n",
      "human-pose-estimation-0005\n",
      "human-pose-estimation-0006\n",
      "human-pose-estimation-0007\n",
      "human-pose-estimation-3d-0001\n",
      "hybrid-cs-model-mri\n",
      "i3d-rgb-tf\n",
      "icnet-camvid-ava-0001\n",
      "icnet-camvid-ava-sparse-30-0001\n",
      "icnet-camvid-ava-sparse-60-0001\n",
      "image-retrieval-0001\n",
      "inception-resnet-v2-tf\n",
      "instance-segmentation-person-0007\n",
      "instance-segmentation-security-0002\n",
      "instance-segmentation-security-0091\n",
      "instance-segmentation-security-0228\n",
      "instance-segmentation-security-1039\n",
      "instance-segmentation-security-1040\n",
      "landmarks-regression-retail-0009\n",
      "license-plate-recognition-barrier-0001\n",
      "license-plate-recognition-barrier-0007\n",
      "machine-translation-nar-de-en-0002\n",
      "machine-translation-nar-en-de-0002\n",
      "machine-translation-nar-en-ru-0002\n",
      "machine-translation-nar-ru-en-0002\n",
      "mask_rcnn_inception_resnet_v2_atrous_coco\n",
      "mask_rcnn_resnet50_atrous_coco\n",
      "midasnet\n",
      "mixnet-l\n",
      "mobilefacedet-v1-mxnet\n",
      "mobilenet-ssd\n",
      "mobilenet-v1-0.25-128\n",
      "mobilenet-v1-1.0-224\n",
      "mobilenet-v1-1.0-224-tf\n",
      "mobilenet-v2\n",
      "mobilenet-v2-1.0-224\n",
      "mobilenet-v2-1.4-224\n",
      "mobilenet-v2-pytorch\n",
      "mobilenet-v3-large-1.0-224-tf\n",
      "mobilenet-v3-small-1.0-224-tf\n",
      "mobilenet-yolo-v4-syg\n",
      "mozilla-deepspeech-0.6.1\n",
      "mozilla-deepspeech-0.8.2\n",
      "mtcnn\n",
      "netvlad-tf\n",
      "nfnet-f0\n",
      "noise-suppression-denseunet-ll-0001\n",
      "noise-suppression-poconetlike-0001\n",
      "ocrnet-hrnet-w48-paddle\n",
      "octave-resnet-26-0.25\n",
      "open-closed-eye-0001\n",
      "pedestrian-and-vehicle-detector-adas-0001\n",
      "pedestrian-detection-adas-0002\n",
      "pelee-coco\n",
      "person-attributes-recognition-crossroad-0230\n",
      "person-attributes-recognition-crossroad-0234\n",
      "person-attributes-recognition-crossroad-0238\n",
      "person-detection-0106\n",
      "person-detection-0200\n",
      "person-detection-0201\n",
      "person-detection-0202\n",
      "person-detection-0203\n",
      "person-detection-0301\n",
      "person-detection-0302\n",
      "person-detection-0303\n",
      "person-detection-action-recognition-0005\n",
      "person-detection-action-recognition-0006\n",
      "person-detection-action-recognition-teacher-0002\n",
      "person-detection-asl-0001\n",
      "person-detection-raisinghand-recognition-0001\n",
      "person-detection-retail-0002\n",
      "person-detection-retail-0013\n",
      "person-reidentification-retail-0277\n",
      "person-reidentification-retail-0286\n",
      "person-reidentification-retail-0287\n",
      "person-reidentification-retail-0288\n",
      "person-vehicle-bike-detection-2000\n",
      "person-vehicle-bike-detection-2001\n",
      "person-vehicle-bike-detection-2002\n",
      "person-vehicle-bike-detection-2003\n",
      "person-vehicle-bike-detection-2004\n",
      "person-vehicle-bike-detection-crossroad-0078\n",
      "person-vehicle-bike-detection-crossroad-1016\n",
      "person-vehicle-bike-detection-crossroad-yolov3-1020\n",
      "product-detection-0001\n",
      "pspnet-pytorch\n",
      "quartznet-15x5-en\n",
      "regnetx-3.2gf\n",
      "repvgg-a0\n",
      "repvgg-b1\n",
      "repvgg-b3\n",
      "resnest-50-pytorch\n",
      "resnet-18-pytorch\n",
      "resnet-34-pytorch\n",
      "resnet-50-pytorch\n",
      "resnet-50-tf\n",
      "resnet18-xnor-binary-onnx-0001\n",
      "resnet50-binary-0001\n",
      "retinaface-resnet50-pytorch\n",
      "retinanet-tf\n",
      "rexnet-v1-x1.0\n",
      "rfcn-resnet101-coco-tf\n",
      "road-segmentation-adas-0001\n",
      "robust-video-matting-mobilenetv3\n",
      "se-inception\n",
      "se-resnet-50\n",
      "se-resnext-50\n",
      "semantic-segmentation-adas-0001\n",
      "shufflenet-v2-x0.5\n",
      "shufflenet-v2-x1.0\n",
      "single-human-pose-estimation-0001\n",
      "single-image-super-resolution-1032\n",
      "single-image-super-resolution-1033\n",
      "smartlab-object-detection-0001\n",
      "smartlab-object-detection-0002\n",
      "smartlab-object-detection-0003\n",
      "smartlab-object-detection-0004\n",
      "smartlab-sequence-modelling-0001\n",
      "squeezenet1.0\n",
      "squeezenet1.1\n",
      "ssd-resnet34-1200-onnx\n",
      "ssd300\n",
      "ssd512\n",
      "ssd_mobilenet_v1_coco\n",
      "ssd_mobilenet_v1_fpn_coco\n",
      "ssdlite_mobilenet_v2\n",
      "swin-tiny-patch4-window7-224\n",
      "t2t-vit-14\n",
      "text-detection-0003\n",
      "text-detection-0004\n",
      "text-image-super-resolution-0001\n",
      "text-recognition-0012\n",
      "text-recognition-0014\n",
      "text-recognition-0015\n",
      "text-recognition-0016\n",
      "text-recognition-resnet-fc\n",
      "text-spotting-0005\n",
      "text-to-speech-en-0001\n",
      "text-to-speech-en-multi-0001\n",
      "time-series-forecasting-electricity-0001\n",
      "ultra-lightweight-face-detection-rfb-320\n",
      "ultra-lightweight-face-detection-slim-320\n",
      "unet-camvid-onnx-0001\n",
      "vehicle-attributes-recognition-barrier-0039\n",
      "vehicle-attributes-recognition-barrier-0042\n",
      "vehicle-detection-0200\n",
      "vehicle-detection-0201\n",
      "vehicle-detection-0202\n",
      "vehicle-detection-adas-0002\n",
      "vehicle-license-plate-detection-barrier-0106\n",
      "vehicle-license-plate-detection-barrier-0123\n",
      "vehicle-reid-0001\n",
      "vgg16\n",
      "vgg19\n",
      "vitstr-small-patch16-224\n",
      "wav2vec2-base\n",
      "wavernn\n",
      "weld-porosity-detection-0001\n",
      "yolact-resnet50-fpn-pytorch\n",
      "yolo-v1-tiny-tf\n",
      "yolo-v2-ava-0001\n",
      "yolo-v2-ava-sparse-35-0001\n",
      "yolo-v2-ava-sparse-70-0001\n",
      "yolo-v2-tf\n",
      "yolo-v2-tiny-ava-0001\n",
      "yolo-v2-tiny-ava-sparse-30-0001\n",
      "yolo-v2-tiny-ava-sparse-60-0001\n",
      "yolo-v2-tiny-tf\n",
      "yolo-v2-tiny-vehicle-detection-0001\n",
      "yolo-v3-onnx\n",
      "yolo-v3-tf\n",
      "yolo-v3-tiny-onnx\n",
      "yolo-v3-tiny-tf\n",
      "yolo-v4-tf\n",
      "yolo-v4-tiny-tf\n",
      "yolof\n",
      "yolox-tiny\n"
     ]
    }
   ],
   "source": [
    "!omz_downloader --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><div class=tip><i><b>Tip: </b>The '!' at the beginning is a special Jupyter* Notebook command that allows you to run shell commands as if you are at a command line. The above command will also work in a terminal (with the '!' removed).</i></div>\n",
    "\n",
    "Some of these downloaded models are already in the IR format, while others will require the Model Optimizer to be run. For our application, we will be using the [`mobilenet-ssd`](https://github.com/opencv/open_model_zoo/tree/master/models/public/mobilenet-ssd) inference model, which will require being optimization using the Model Optimizer to create the model in the necessary IR format neede by the Inference Engine to run. \n",
    "\n",
    "The format for the Model Downloader command to download a model is:\n",
    "```bash\n",
    "/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py \\\n",
    "    --name <model_name> -o <output_directory>\n",
    "```\n",
    "The input arguments are as follows:\n",
    "- **--name** : The name of the model you want to download. It should be one of the models listed in the previous cell.\n",
    "- **-o** : The output directory where to store the downloaded model. If the directory does not exist, it will be created.\n",
    "\n",
    "Run the following cell to download the `mobilenet-ssd` model to the `./raw_models` directory relative to the location of this Jupyter* Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nAll files that were downloaded:\n",
      "./raw_models\n",
      "./raw_models/public\n",
      "./raw_models/public/mobilenet-ssd\n",
      "./raw_models/public/mobilenet-ssd/mobilenet-ssd.prototxt\n",
      "./raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel\n"
     ]
    }
   ],
   "source": [
    "#!downloader.py --name mobilenet-ssd -o raw_models\n",
    "!mkdir -p raw_models/public\n",
    "!cp -r  /data/reference-sample-data/raw_models/mobilenet-ssd raw_models/public\n",
    "!echo \"\\nAll files that were downloaded:\"\n",
    "!find ./raw_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view a graph of the model used in this application, run the cell below then select the link generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169729d8b83e405a86ebb622bc8a5012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='View model graph:  <span title=\"View model\">&#128065; </span><a target=\\'_blank\\' href=\\'/services…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showModelVisualizerLink(\"raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above from the output of the last `!find...` command, the necessary model files created using the Caffe* framework have been downloaded:\n",
    "- **mobilenet-ssd.prototxt** - The deployed [Protocol Buffer](https://developers.google.com/protocol-buffers) file that describes the network architecture to run inference\n",
    "- **mobilenet-ssd.caffemodel** - Binary containing trained weights\n",
    "\n",
    "These files will need to be optimized using the Model Optimizer to create the necessary IR files.  We will be running the inference model on different hardware devices which have different requirements on the precision of the model (see [Inference Engine Supported Model Formats](https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_Supported_Devices.html#supported_model_formats) for details).  For our purposes, we will focus on the use of the two most common precisions, FP32 and FP16.\n",
    "\n",
    "For this model, we will run the Model Optimizer using the format:\n",
    "```bash\n",
    "mo \\\n",
    "    --input_model <path_to_caffemodel> \\\n",
    "    --data_type <data_precision> \\\n",
    "    --output_dir <path_to_output_directory> \\\n",
    "    --scale <scale_value> \\\n",
    "    --mean_values [<channel_mean_values>] \n",
    "```\n",
    "\n",
    "The input arguments are as follows:\n",
    "- **--input_model** : The model's input *.caffemodel* file  (the *.prototxt* with the same base name will be automatically found, otherwise the `--input_proto` argument would need to be specified)\n",
    "- **--data_type** : The model's data type and precision (e.g. FP16, FP32, INT8, etc.)\n",
    "- **--output_dir** : Output directory where to store the generated IR model files\n",
    "- **--scale** : Scaling (divide by) value to apply to input values\n",
    "- **--mean_values** : Mean values (one per channel) to be subtracted from input values before scaling\n",
    "\n",
    "\n",
    "For converting our model, we will use the typical scaling value `256` and mean values `[127,127,127]` used with Caffe* models.  The complete command will look like the following:\n",
    "```bash\n",
    "!mo \\\n",
    "    --input_model raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel \\\n",
    "    --data_type <data_precision> \\\n",
    "    --output_dir models/mobilenet-ssd/<data_precision> \\\n",
    "    --scale 256 \\\n",
    "    --mean_values [127,127,127] \n",
    "```\n",
    "We will run the command twice, first with <*data_precision*> set to `FP16` and then `FP32` to get all the IR files we will need to run inference on different devices.\n",
    "\n",
    "<br><div class=note><i><b>Note: </b>More information on how to use Model Optimizer to convert Caffe* models may be found at:[Converting a Caffe* Model](https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Caffe.html)</i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to use the Model Optimizer to create the `FP16` and `FP32` model IR files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u58506/ai_workshop/Lab3/object-detection-python/raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u58506/ai_workshop/Lab3/object-detection-python/models/mobilenet-ssd/FP16\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/openvino/tools/mo/utils/../front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u58506/ai_workshop/Lab3/object-detection-python/raw_models/public/mobilenet-ssd/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \t/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/openvino/tools/mo/utils/../../extensions/front/caffe/CustomLayersMapping.xml\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "OpenVINO runtime found in: \t/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "Model Optimizer version: \t2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnetworkx: installed: 2.5.1, required: ~= 2.6\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev[caffe]\n",
      "/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/numpy/lib/function_base.py:792: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, order=order, subok=subok, copy=True)\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/u58506/ai_workshop/Lab3/object-detection-python/models/mobilenet-ssd/FP16/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u58506/ai_workshop/Lab3/object-detection-python/models/mobilenet-ssd/FP16/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 12.54 seconds. \n",
      "[ SUCCESS ] Memory consumed: 170 MB. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u58506/ai_workshop/Lab3/object-detection-python/raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u58506/ai_workshop/Lab3/object-detection-python/models/mobilenet-ssd/FP32\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/openvino/tools/mo/utils/../front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u58506/ai_workshop/Lab3/object-detection-python/raw_models/public/mobilenet-ssd/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \t/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/openvino/tools/mo/utils/../../extensions/front/caffe/CustomLayersMapping.xml\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "OpenVINO runtime found in: \t/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "Model Optimizer version: \t2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnetworkx: installed: 2.5.1, required: ~= 2.6\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev[caffe]\n",
      "/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/numpy/lib/function_base.py:792: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, order=order, subok=subok, copy=True)\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/u58506/ai_workshop/Lab3/object-detection-python/models/mobilenet-ssd/FP32/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u58506/ai_workshop/Lab3/object-detection-python/models/mobilenet-ssd/FP32/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 13.68 seconds. \n",
      "[ SUCCESS ] Memory consumed: 170 MB. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai\n",
      "\\nAll IR files that were created:\n",
      "./models/mobilenet-ssd/FP16/mobilenet-ssd.bin\n",
      "./models/mobilenet-ssd/FP16/mobilenet-ssd.xml\n",
      "./models/mobilenet-ssd/INT8/optimized/mobilenet-ssd.bin\n",
      "./models/mobilenet-ssd/INT8/optimized/mobilenet-ssd.xml\n",
      "./models/mobilenet-ssd/FP32/mobilenet-ssd.bin\n",
      "./models/mobilenet-ssd/FP32/mobilenet-ssd.xml\n"
     ]
    }
   ],
   "source": [
    "# Create FP16 IR files\n",
    "!mo \\\n",
    "--input_model raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel \\\n",
    "--data_type FP16 \\\n",
    "--output_dir models/mobilenet-ssd/FP16 \\\n",
    "--scale 256 \\\n",
    "--mean_values [127,127,127] \n",
    "\n",
    "# Create FP32 IR files\n",
    "!mo \\\n",
    "--input_model raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel \\\n",
    "--data_type FP32 \\\n",
    "--output_dir models/mobilenet-ssd/FP32 \\\n",
    "--scale 256 \\\n",
    "--mean_values [127,127,127] \n",
    "\n",
    "# find all resulting IR files\n",
    "!echo \"\\nAll IR files that were created:\"\n",
    "!find ./models -name \"*.xml\" -o -name \"*.bin\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above from the output of the last `!find...` command, the required sets of IR model files (`*.xml` and `*.bin`) have been created.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create INT8 precision IR  using Post-Training Optimization Toolkit (POT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Post-Training Optimization Toolkit is designed to convert a model into a more hardware-accelerated representation by applying specific methods that do not require re-training, for example, post-training quantization.\n",
    "\n",
    "In this example, we wil take the FP32 precision model IR from the previous section convert it to INT8 precision model IR using **defaultquantization** which is the fast method of quantization. Their are other quantization algorithms and techniques to optimize your model check [here](https://docs.openvinotoolkit.org/latest/_README.html) for more information.\n",
    "\n",
    "Optionally, to use this sample with another model and dataset you will need to take a look at the config files in the config folder and supply the proper paths to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Post-Training Optimization Tool\n",
    "\n",
    "To get familiar with the arguments let's run the Post-training Optimization Toolkit usage menu. Then we will run the tool to convert the FP32 IR generated above to INT8 IR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Training Optimization Tool Usage Menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: pot [-h] [-c CONFIG] [-q {default,accuracy_aware}]\n",
      "           [--preset {performance,mixed}] [-m MODEL] [-w WEIGHTS]\n",
      "           [--name NAME] [--engine {accuracy_checker,simplified}]\n",
      "           [--ac-config AC_CONFIG] [--max-drop MAX_DROP] [-e]\n",
      "           [--output-dir OUTPUT_DIR] [-d]\n",
      "           [--log-level {CRITICAL,ERROR,WARNING,INFO,DEBUG}] [--progress-bar]\n",
      "           [--stream-output] [--keep-uncompressed-weights]\n",
      "           [--data-source DATA_SOURCE]\n",
      "\n",
      "Post-training Compression Toolkit\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -c CONFIG, --config CONFIG\n",
      "                        Path to a config file with optimization parameters.\n",
      "                        Overrides \"-q | -m | -w | --ac-config | --engine\"\n",
      "                        options\n",
      "  -q {default,accuracy_aware}, --quantize {default,accuracy_aware}\n",
      "                        Quantize model to 8 bits with specified quantization\n",
      "                        method: default | accuracy_aware\n",
      "  --preset {performance,mixed}\n",
      "                        Use \"performance\" for fully symmetric quantization or\n",
      "                        \"mixed\" preset for symmetric quantization of weight\n",
      "                        and asymmetric quantization of activations. Applicable\n",
      "                        only when -q option is used.\n",
      "  -m MODEL, --model MODEL\n",
      "                        Path to the model file (.xml). Applicable only when -q\n",
      "                        option is used.\n",
      "  -w WEIGHTS, --weights WEIGHTS\n",
      "                        Path to the weights file (.bin). Applicable only when\n",
      "                        -q option is used.\n",
      "  --name NAME, -n NAME  Model name. Applicable only when -q option is used.\n",
      "  --engine {accuracy_checker,simplified}\n",
      "                        Engine type. Default: `accuracy_checker`\n",
      "  --ac-config AC_CONFIG\n",
      "                        Path to the Accuracy Checker configuration file.\n",
      "                        Applicable only when -q option is used.\n",
      "  --max-drop MAX_DROP   Maximum accuracy drop. Valid only for accuracy-aware\n",
      "                        quantization. Applicable only when -q option is used.\n",
      "  -e, --evaluate        Whether to evaluate model on whole dataset\n",
      "  --output-dir OUTPUT_DIR\n",
      "                        The directory where models are saved. Default:\n",
      "                        ./results\n",
      "  -d, --direct-dump     Flag to save files without sub folders with algo names\n",
      "  --log-level {CRITICAL,ERROR,WARNING,INFO,DEBUG}\n",
      "                        Log level to print\n",
      "  --progress-bar        Disable CL logging and enable progress bar\n",
      "  --stream-output       Switch progress display to a multiline mode\n",
      "  --keep-uncompressed-weights\n",
      "                        Keep Convolution, Deconvolution and FullyConnected\n",
      "                        weights uncompressed\n",
      "  --data-source DATA_SOURCE\n",
      "                        Valid only for Simplified modes. Path to dataset dir\n",
      "                        is required.\n"
     ]
    }
   ],
   "source": [
    "!pot -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert mobilenet-ssd FP32 IR to INT8 IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:openvino.tools.pot.app.run:Output log dir: models/mobilenet-ssd/INT8/\n",
      "INFO:openvino.tools.pot.app.run:Creating pipeline:\n",
      " Algorithm: DefaultQuantization\n",
      " Parameters:\n",
      "\tstat_subset_size           : 10\n",
      "\ttarget_device              : CPU\n",
      "\tpreset                     : performance\n",
      "\tmodel_type                 : None\n",
      "\tdump_intermediate_model    : False\n",
      "\tinplace_statistics         : True\n",
      "\texec_log_dir               : models/mobilenet-ssd/INT8/\n",
      " ===========================================================================\n",
      "IE version: 2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "Loaded CPU plugin version:\n",
      "    CPU - openvino_intel_cpu_plugin: 2022.1.2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "Annotation conversion for VOC2012 dataset has been started\n",
      "Parameters to be used for conversion:\n",
      "converter: voc_detection\n",
      "annotations_dir: dataset/VOCdevkit/VOC2012/Annotations\n",
      "images_dir: dataset/VOCdevkit/VOC2012/JPEGImages\n",
      "imageset_file: dataset/VOCdevkit/VOC2012/ImageSets/Main/val.txt\n",
      "Annotation conversion for VOC2012 dataset has been finished\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Inference Engine version:                2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Model Optimizer version:                 2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Post-Training Optimization Tool version: 2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "INFO:openvino.tools.pot.statistics.collector:Start computing statistics for algorithms : DefaultQuantization\n",
      "INFO:openvino.tools.pot.statistics.collector:Computing statistics finished\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Start algorithm: DefaultQuantization\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Start computing statistics for algorithm : ActivationChannelAlignment\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Computing statistics finished\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Start computing statistics for algorithms : MinMaxQuantization,FastBiasCorrection\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Computing statistics finished\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Finished: DefaultQuantization\n",
      " ===========================================================================\n"
     ]
    }
   ],
   "source": [
    "!pot -c config/mobilenet-ssd.yml --output-dir models/mobilenet-ssd/INT8/ -d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference\n",
    "The following sections will go through the steps to run our inference application on the Intel® DevCloud for the Edge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure input\n",
    "For convenience and consistency, in the next cell we set the Python* variable `InputVideo` to the input video file we will be using to run our sample application.  In addition, the variable `NumRequests_*` is set to maximum number of inference requests to make for each architecture while using the Async API.  The variables `NumRequests_*` are set accordingly to improve performance.  \n",
    "\n",
    "<br><div class=note><i><b>Note: </b>\n",
    "If you want to use a different input video, change the path in the following cell to the path of the video and run the cell again.  Also, if you want to change the number of inference requests, make the necessary change in the following cell and run the cell again.\n",
    "</i></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input video file set to:/data/reference-sample-data/object-detection-python/cars_1900.mp4\n",
      "Number of inference requests for CPU set to:2\n",
      "Number of inference requests for GPU set to:4\n",
      "Number of inference requests for NCS2 set to:4\n",
      "Number of inference requests for HDDL-R set to:128\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the input video to use for the rest of this sample\n",
    "InputVideo = \"/data/reference-sample-data/object-detection-python/cars_1900.mp4\"\n",
    "print(f\"Input video file set to:{InputVideo}\")\n",
    "\n",
    "# Set maximum number of inference requests for CPU when using the Async API\n",
    "NumRequests_CPU = 2\n",
    "print(f\"Number of inference requests for CPU set to:{NumRequests_CPU}\")\n",
    "\n",
    "# Set maximum number of inference requests for CPU when using the Async API\n",
    "NumRequests_GPU = 4\n",
    "print(f\"Number of inference requests for GPU set to:{NumRequests_GPU}\")\n",
    "\n",
    "# Set maximum number of inference requests for NCS2 when using the Async API\n",
    "NumRequests_NCS2 = 4\n",
    "print(f\"Number of inference requests for NCS2 set to:{NumRequests_NCS2}\")\n",
    "\n",
    "# Set maximum number of inference requests for HDDL-R when using the Async API\n",
    "NumRequests_HDDLR = 128\n",
    "print(f\"Number of inference requests for HDDL-R set to:{NumRequests_HDDLR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional exercise: View input without inference\n",
    "\n",
    "If you are curious to see the input video, run the following cell to view the original video stream used for inference and this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Cars Video</h2>\n",
       "    \n",
       "    <video alt=\"\" controls autoplay muted height=\"480\"><source src=\"./data/reference-sample-data/object-detection-python/cars_1900.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create link and adjust video path to be able to display from /data using videoHTML()\n",
    "!ln -sfn /data data\n",
    "videoHTML('Cars Video', [\".\"+InputVideo if InputVideo.startswith('/') else InputVideo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional adjustment of output video frame rate and size\n",
    "\n",
    "Video rendering is performed by the separate Python* executable `object_detection_annotate.py` at the end of the job script. To reduce rendering time, you may reduce the output video quality using the `SCALE_FRAME_RATE` and `SCALE_RESOLUTION` variables. \n",
    "\n",
    "- Setting `SCALE_FRAME_RATE` to:\n",
    " - =1 writes all processed video frames with bounding boxes into the output video. This is the slowest option and it preserves all inferred data in the output video stream.  \n",
    " - =2 writes every other frame of the processed frames into the output video.  This scales the number of output video frames by half (1/2).\n",
    "\n",
    "\n",
    "- Setting `SCALE_RESOLUTION` to:\n",
    " - =1 produces the output video with the same resolution as the input video.  This is the slowest option.\n",
    " - <1 reduces the output video resolution. In the job script we have `SCALE_RESOLUTION=0.5` which sets the output video resolution in each dimension to 50% of the input video's resolution.\n",
    "\n",
    "<br><div class=note><i><b>Note: </b>Changes to `SCALE_FRAME_RATE` or `SCALE_RESOLUTION` are made to the job file which appears in a later section and the job file must be written whenever changes are made.</i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the job file\n",
    "We will run inference on several different edge compute nodes present in the Intel® DevCloud for the Edge. We will send work to the edge compute nodes by submitting the corresponding non-interactive jobs into a queue. For each job, we will specify the type of the edge compute server that must be allocated for the job.\n",
    "\n",
    "The job file is a [Bash](https://www.gnu.org/software/bash/) script that serves as a wrapper around the Python* executable of our application that will be executed directly on the edge compute node.  One purpose of the job file is to simplify running an application on different compute nodes by accepting a few arguments and then performing accordingly any necessary steps before and after running the application executable.  \n",
    "\n",
    "For this sample, the job file we will be using is already written for you and appears in the next cell.  The job file will be submitted as if it were run from the command line using the following format:\n",
    "```bash\n",
    "object_detection_job.sh <output_directory> <device> <fp_precision> <input_file> <num_reqs>\n",
    "```\n",
    "Where the job file input arguments are:\n",
    "- <*output_directory*> - Output directory to use to store output files\n",
    "- <*device*> - Hardware device to use (e.g. CPU, GPU, etc.)\n",
    "- <*fp_precision*> - Which floating point precision inference model to use (FP32 or FP16)\n",
    "- <*input_file*> - Path to input video file\n",
    "- <*num_reqs*> - The maximum number of requests to allow while using the Async API\n",
    "\n",
    "Based on the input arguments, the job file will do the following:\n",
    "- Change to the working directory `PBS_O_WORKDIR` where this Jupyter* Notebook and other files appear on the compute node\n",
    "- Create the <*output_directory*>\n",
    "- Choose the appropriate inference model IR file for the specified <*fp_precision*>\n",
    "- Run the application Python* executable with the appropriate command line arguments\n",
    "- Run the application annotator Python* executable with the appropriate command line arguments\n",
    "\n",
    "Run the following cell to create the `object_detection_job.sh` job file.  The [`%%writefile`](https://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-writefile) line at the top will write the cell contents to the specified job file `object_detection_job.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting object_detection_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile object_detection_job.sh\n",
    "\n",
    "# Store input arguments: <output_directory> <device> <fp_precision> <input_file> <num_reqs>\n",
    "OUTPUT_FILE=$1\n",
    "DEVICE=$2\n",
    "FP_MODEL=$3\n",
    "INPUT_FILE=$4\n",
    "NUM_REQS=$5\n",
    "\n",
    "echo VENV_PATH=$VENV_PATH\n",
    "echo OPENVINO_RUNTIME=$OPENVINO_RUNTIME\n",
    "echo INPUT_FILE=$INPUT_FILE\n",
    "echo FP_MODEL=$FP_MODEL\n",
    "echo INPUT_TILE=$INPUT_FILE\n",
    "echo NUM_REQS=$NUM_REQS\n",
    "\n",
    "# Follow this order of setting up environment for openVINO 2022.1.0.553\n",
    "echo \"Activating a Python virtual environment from ${VENV_PATH}...\"\n",
    "source ${VENV_PATH}/bin/activate\n",
    "echo \"Activating OpenVINO variables from ${OPENVINO_RUNTIME}...\"\n",
    "source ${OPENVINO_RUNTIME}/setupvars.sh\n",
    "\n",
    "\n",
    "# The default path for the job is the user's home directory,\n",
    "#  change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "# Make sure that the output directory exists.\n",
    "mkdir -p $OUTPUT_FILE\n",
    "\n",
    "# Set inference model IR files using specified precision\n",
    "MODELPATH=models/mobilenet-ssd/${FP_MODEL}/mobilenet-ssd.xml\n",
    "LABEL_FILE=./labels.txt\n",
    "\n",
    "# Run the object detection code\n",
    "python3 object_detection.py -m $MODELPATH \\\n",
    "                            -i $INPUT_FILE \\\n",
    "                            -o $OUTPUT_FILE \\\n",
    "                            -d $DEVICE \\\n",
    "                            -nireq $NUM_REQS \\\n",
    "                            --labels $LABEL_FILE\n",
    "\n",
    "# Run the output video annotator code\n",
    "SCALE_FRAME_RATE=1    # scale number or output frames to input frames\n",
    "SCALE_RESOLUTION=0.5  # scale output frame resolution \n",
    "python3 object_detection_annotate.py -i $INPUT_FILE \\\n",
    "                                     -o $OUTPUT_FILE \\\n",
    "                                     -f $SCALE_FRAME_RATE \\\n",
    "                                     -s $SCALE_RESOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to submit a job\n",
    "\n",
    "Now that we have the job script, we can submit jobs to edge compute nodes in the Intel® DevCloud for the Edge.  To submit a job, the `qsub` command is used with the following format:\n",
    "```bash\n",
    "qsub <job_file> -N <JobName> -l <nodes> -F \"<job_file_arguments>\" \n",
    "```\n",
    "We can submit object_detection_job.sh to several different types of edge compute nodes simultaneously or just one node at a time.\n",
    "\n",
    "There are three options of `qsub` command that we use for this:\n",
    "- <*job_file*> - This is the job file we created in the previous step\n",
    "- `-N` <*JobName*> : Sets name specific to the job so that it is easier to distinguish  between it and other jobs\n",
    "- `-l` <*nodes*> - Specifies the number and the type of nodes using the format *nodes*=<*node_count*>:<*property*>[:<*property*>...]\n",
    "- `-F` \"<*job_file_arguments*>\" - String containing the input arguments described in the previous step to use when running the job file\n",
    "\n",
    "*(Optional)*: To see the available types of nodes on the Intel® DevCloud for the Edge, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15 idc001skl,compnode,openvino-latest,intel-core,i5-6500te,intel-hd-530,ram8gb\n",
      "     14 idc002mx8,compnode,openvino-latest,intel-core,i5-6500te,intel-hd-530,ram8gb,myriadx-8-vpu\n",
      "     11 idc004nc2,compnode,openvino-latest,intel-core,i5-6500te,intel-hd-530,ram8gb,myriadx-1-vpu\n",
      "      5 idc006kbl,compnode,openvino-latest,intel-core,i5-7500t,intel-hd-630,ram8gb\n",
      "      5 idc007xv5,compnode,openvino-latest,intel-xeon,e3-1268l-v5,intel-hd-p530,ram32gb\n",
      "      5 idc008u2g,compnode,openvino-latest,intel-atom,e3950,intel-hd-505,ram4gb,myriadx-1-vpu\n",
      "      1 idc009jkl,compnode,openvino-latest,intel-core,i5-7500,intel-hd-630,ram8gb\n",
      "      1 idc010jal,compnode,openvino-latest,intel-celeron,j3355,intel-hd-500,ram4gb\n",
      "      1 idc011ark2250s,compnode,openvino-latest,intel-core,i5-6442eq,intel-hd-530,ram8gb,myriadx-3-vpu\n",
      "      1 idc012ark1220l,compnode,openvino-latest,intel-atom,e3940,intel-hd-500,ram4gb,myriadx-2-vpu\n",
      "      1 idc013ds580,compnode,openvino-latest,intel-atom,e3950,intel-hd-505,ram2gb\n",
      "      4 idc014,compnode,openvino-latest,intel-core,i7-8665ue,intel-uhd-620,ram16gb,myriadx-2-vpu\n",
      "      3 idc015ai5,compnode,openvino-latest,intel-core,i5-8365ue,intel-uhd-620,ram8gb\n",
      "      2 idc016ai7,compnode,openvino-latest,intel-core,i7-8665ue,intel-uhd-620,ram16gb\n",
      "      1 idc017,compnode,openvino-latest,intel-xeon,gold5220r,no-gpu,ram96gb\n",
      "      1 idc018,compnode,openvino-latest,intel-xeon,gold6258r,no-gpu,ram96gb\n",
      "      2 idc021,compnode,openvino-latest,intel-xeon,silver4214r,no-gpu,ram48gb\n",
      "     10 idc022,compnode,openvino-latest,intel-core,i7-10710u,intel-uhd-620,ram16gb\n",
      "      6 idc023,compnode,openvino-latest,intel-core,i5-8365ue,intel-uhd-620,ram8gb,myriadx-2-vpu\n",
      "      1 idc024,compnode,openvino-latest,intel-xeon,gold5220r,no-gpu,ram96gb,myriadx-8-vpu\n",
      "      1 idc026,compnode,openvino-latest,intel-xeon,bronze3206r,no-gpu,ram48gb,myriadx-8-vpu\n",
      "      1 idc027,compnode,openvino-latest,intel-xeon,silver4214r,no-gpu,ram48gb,myriadx-8-vpu\n",
      "      1 idc029,compnode,openvino-latest,intel-core,i7-8665u,intel-uhd-620,ram32gb\n",
      "      1 idc030,compnode,openvino-latest,intel-core,i7-1065g7,iris-plus,ram16gb\n",
      "      1 idc031,compnode,openvino-latest,intel-xeon,e-2286m,intel-uhd-p630,ram32gb,myriadx-8-vpu\n",
      "     14 idc033,compnode,openvino-latest,intel-xeon,e-2286m,intel-uhd-p630,ram32gb\n",
      "      5 idc036,compnode,openvino-latest,intel-core,i9-10900t,intel-uhd-630,ram32gb\n",
      "      5 idc037,compnode,openvino-latest,intel-core,i7-10700t,intel-uhd-630,ram32gb\n",
      "      5 idc038,compnode,openvino-latest,intel-core,i5-8365ue,intel-uhd-620,ram8gb,myriadx-2-vpu\n",
      "      1 idc042,compnode,openvino-latest,intel-core,i5-8500t,intel-uhd-630,ram32gb,myriadx-8-vpu,aaeon,boxer-6842m\n",
      "      1 idc043,compnode,openvino-latest,intel-core,i3-10100te,intel-uhd-630,ram16gb,myriadx-2-vpu,aaeon,genesys-cml5ai\n",
      "      1 idc044,compnode,openvino-latest,intel-atom,intel,atom,e3950,intel-uhd-630,ram8gb,myriadx-1-vpu\n",
      "      5 idc045,compnode,openvino-latest,intel-core,i7-1185g7e,iris-xe-graphics,ram16gb,none\n",
      "      2 idc046,compnode,openvino-latest,intel-core,i5-1145g7e,iris-xe-graphics,ram16gb\n",
      "      1 idc051,compnode,openvino-latest,intel-xeon,gold6314u,none,ram128gb,none,icelake\n",
      "      5 idc052,compnode,openvino-latest,intel-xeon,gold6338n,none,ram128gb,none,icelake\n",
      "      2 idc053,compnode,openvino-latest,intel-xeon,d-2166nt,none,128gb,none\n",
      "      1 idc054,compnode,openvino-latest,intel-core,i7-1165g7,iris-xe-graphics,ram16gb,none\n",
      "      1 idc055,compnode,openvino-latest,intel-core,i5-1145g7e,iris-xe-graphics,ram8gb,none\n",
      "      1 idc056,compnode,openvino-latest,intel-core,i3-1115g4e,intel-uhd-11th-gen,ram8gb,none\n",
      "      1 idc057,compnode,openvino-latest,intel-core,i5-7500t,intel-hd-630,ram8gb,myriadx-1-vpu\n",
      "      2 idc058,compnode,openvino-latest,intel-core,i5-8265u,intel-uhd-8th-gen,ram8gb,none\n",
      "      1 idc060,compnode,openvino-latest,intel-core,i5-8500,intel-uhd-p630,ram16gb,none\n",
      "      1 idc061,compnode,openvino-latest,intel-xeon,e-2176g,intel-uhd-p630,ram16gb,none\n",
      "      1 idc062,compnode,openvino-latest,intel-celeron,6305e,intel-uhd-graphics,ram16gb,none\n",
      "      5 idc063,compnode,openvino-latest,intel-core,xeon,w-1290te,intel-uhd-630,ram16gb,none\n",
      "      2 idc065,compnode,openvino-latest,intel-core,i7-8565u,intel-uhd-8th-gen,ram8gb,none\n",
      "      1 idc066,compnode,openvino-latest,intel-core,i3-8145u,intel-uhd-8th-gen,ram4gb,none\n",
      "      1 idc068,compnode,openvino-latest,intel-core,i7-1185g7e,iris-xe-graphics,ram16gb,none\n",
      "      1 idc069,compnode,openvino-latest,intel-core,i5-1135g7,iris-xe-graphics,ram8gb,none\n",
      "     10 idc070,compnode,openvino-latest,intel-pentium,j6426,intel-uhd-10th-gen,ram4gb,none\n",
      "     10 idc071,compnode,openvino-latest,intel-atom,x6425re,intel-uhd-10th-gen,ram16gb,none\n"
     ]
    }
   ],
   "source": [
    "!pbsnodes | grep compnode | awk '{print $3}' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above output from executing the previous cell, the properties describe the node, and the number on the left is the number of available nodes of that architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit jobs\n",
    "\n",
    "Each of the cells in the subsections below will submit a job to be run on different edge compute nodes. The output of each cell is the _JobID_ for the submitted job.  The _JobID_ can be used to track the status of the job.  After submission, a job will go into a waiting queue before running once the requested compute nodes become available.\n",
    "\n",
    "<br><div class=note><i><b>Note: </b>You may submit all jobs at once or one at a time.</i></div> \n",
    "\n",
    "<br><div class=tip><b>Tip: </b>**Shift+Enter** will run the cell and automatically move you to the next cell. This allows you to use **Shift+Enter** multiple times to quickly run through multiple cells, including markdown cells.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submit to an edge compute node with an Intel® CPU\n",
    "In the cell below, we submit a job to an edge node with an [Intel® Core™ i5-6500TE](https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz.html) processor. The inference workload will run on the CPU.\n",
    "\n",
    " \n",
    "   Currently the job is written to run with **FP32 IR** or if you'd like to run with **INT8 IR** supply the -f argument with INT8/optimized which is the relative path to the INT8 IR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466305.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e00eea72494ab789b57dd12121e465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcd6d04dd5647f18826b7fb98d89396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce3d0ded9184314ba0af7f2354f710a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_core_cpu_fp32 = !qsub object_detection_job.sh -l nodes=1:idc002mx8 -F \"results/core_cpu_fp32/ CPU FP32 {InputVideo} {NumRequests_CPU}\" -N obj_det_core -v VENV_PATH,OPENVINO_RUNTIME\n",
    "print(job_id_core_cpu_fp32[0])\n",
    "#Progress indicators\n",
    "if job_id_core_cpu_fp32:\n",
    "    progressIndicator('results/core_cpu_fp32', f'pre_progress_{job_id_core_cpu_fp32[0]}.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/core_cpu_fp32', f'i_progress_{job_id_core_cpu_fp32[0]}.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/core_cpu_fp32', f'post_progress_{job_id_core_cpu_fp32[0]}.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466306.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48386286f594657b620bcaa9d999e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b7adf94cd54d68b1e5813ca787d4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ae7d051aec42ada1a78fa485b920da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_core_cpu_int8 = !qsub object_detection_job.sh -l nodes=1:idc002mx8 -F \"results/core_cpu_int8/ CPU INT8/optimized {InputVideo} {NumRequests_CPU}\" -N obj_det_core -v VENV_PATH,OPENVINO_RUNTIME\n",
    "print(job_id_core_cpu_int8[0])\n",
    "#Progress indicators\n",
    "if job_id_core_cpu_int8:\n",
    "    progressIndicator('results/core_cpu_int8', f'pre_progress_{job_id_core_cpu_int8[0]}.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/core_cpu_int8', f'i_progress_{job_id_core_cpu_int8[0]}.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/core_cpu_int8', f'post_progress_{job_id_core_cpu_int8[0]}.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466307.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80ea823a9324ca5821e5e7eeec0447f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85513739ee4a4f35adcabddc828d31ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018c6b712f3849c39cd7df137f45e8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_core_gpu_fp16 = !qsub object_detection_job.sh -l nodes=1:idc002mx8 -F \"results/core_gpu_fp16/ GPU FP16 {InputVideo} {NumRequests_GPU}\" -N obj_det_core -v VENV_PATH,OPENVINO_RUNTIME\n",
    "print(job_id_core_gpu_fp16[0])\n",
    "#Progress indicators\n",
    "if job_id_core_gpu_fp16:\n",
    "    progressIndicator('results/core_gpu_fp16', f'pre_progress_{job_id_core_gpu_fp16[0]}.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/core_gpu_fp16', f'i_progress_{job_id_core_gpu_fp16[0]}.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/core_gpu_fp16', f'post_progress_{job_id_core_gpu_fp16[0]}.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466308.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5192513b19174ad18336ec0e3ba08001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293d0978cda54deab03d475791156a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9d0f9f15234e92808238b19329b9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_core_hddl_fp16 = !qsub object_detection_job.sh -l nodes=1:idc002mx8 -F \"results/core_hddl_fp16/ HDDL FP16 {InputVideo} {NumRequests_HDDLR}\" -N obj_det_ncs2 -v VENV_PATH,OPENVINO_RUNTIME\n",
    "print(job_id_core_hddl_fp16[0])\n",
    "#Progress indicators\n",
    "if job_id_core_hddl_fp16:\n",
    "    progressIndicator('results/core_hddl_fp16', f'pre_progress_{job_id_core_hddl_fp16[0]}.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/core_hddl_fp16', f'i_progress_{job_id_core_hddl_fp16[0]}.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/core_hddl_fp16', f'post_progress_{job_id_core_hddl_fp16[0]}.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466309.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bdba373f34461b840c58097426817d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d66a61829564baf95fced0d2bf0caca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e87495584c4b0ea8d875457bda71d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_core_multi_fp16 = !qsub object_detection_job.sh -l nodes=1:idc002mx8 -F \"results/core_multi_fp16/ MULTI:GPU,CPU FP16 {InputVideo} {NumRequests_CPU}\" -N obj_det_core -v VENV_PATH,OPENVINO_RUNTIME\n",
    "print(job_id_core_multi_fp16[0])\n",
    "#Progress indicators\n",
    "if job_id_core_multi_fp16:\n",
    "    progressIndicator('results/core_multi_fp16', f'pre_progress_{job_id_core_multi_fp16[0]}.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/core_multi_fp16', f'i_progress_{job_id_core_multi_fp16[0]}.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/core_multi_fp16', f'post_progress_{job_id_core_multi_fp16[0]}.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submit to an edge compute node with Intel® Atom® and using the integrated Intel® GPU\n",
    "In the cell below, we submit a job to an edge node with an [Intel® Atom® x7-E3950](https://ark.intel.com/products/96488/Intel-Atom-x7-E3950-Processor-2M-Cache-up-to-2-00-GHz.html) processor. The inference workload will run on the integrated Intel® HD Graphics 505 GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor job status\n",
    "\n",
    "To check the status of the jobs that have been submitted, use the `qstat` command.  The custom Jupyter* Notebook widget `liveQstat()` is provided to display the output of `qstat` with live updates.  \n",
    "\n",
    "Run the following cell to display the current job status with periodic updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04901a40f5ed47948f9aa5582840094d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid gray', height='200px', overflow_y='auto', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bf9cb9ac2040e08ed317d28b1ac416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the jobs that you have submitted (referenced by the `JobID` that gets displayed right after you submit the jobs in the previous step).\n",
    "There should also be an extra job in the queue named `jupyterhub-singleuser`: this job is your current Jupyter* Notebook session which is always running.\n",
    "\n",
    "The `S` column shows the current status of each job: \n",
    "- If the status is `Q`, then the job is queued and waiting for available resources\n",
    "- If ste status is `R`, then the job is running\n",
    "- If the job is no longer listed, then the job has completed\n",
    "\n",
    "<br><div class=note><i><b>\n",
    "Note: The amount of time spent in the queue depends on the number of users accessing the requested compute nodes. Once the jobs for this sample application begin to run, they should take from 1 to 5 minutes each to complete.\n",
    "</b></i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><div class=danger><b>Wait!: </b>Please wait for the inference jobs and video rendering to complete before proceeding to the next step to view results.</div>\n",
    "\n",
    "### View results\n",
    "\n",
    "Once the jobs have completed, the queue system outputs the stdout and stderr streams of each job into files with names of the forms <*JobName*>.o<*JobID*> and <*JobName*>.e<*JobID*>, respecitvely.  The *JobName* corresponds to the `-N` option when submitting the job using the `qsub` command.  \n",
    "\n",
    "The output video file for each job is written to the file `output_{job_id}.mp4` located in the directory `results/<device>` that was specified as the output directory to the job file.  We will now use the `videoHTML()` utility to display the output video files within this Jupyter* notebook.  Calling `videoHTML()` from a Python* cell follows the form:\n",
    "```python\n",
    "videoHTML(title, [list_of_video_files], statistics(optional))\n",
    "```\n",
    "The parameters are:\n",
    "- *title* - Title to put at the top of the displayed output\n",
    "- \\[*list_of_video_files*\\] - Python* list of video files to display\n",
    "- *statistics(optional)* - Optional statistics file containing the number of seconds it took to process a number of frames\n",
    "\n",
    "Run the cells below to display the videos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### View results from an Intel® CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Intel Core CPU</h2>\n",
       "    <p>3000 \n",
       " frames processed in 38 \n",
       " seconds</p>\n",
       "    <video alt=\"\" controls autoplay muted height=\"480\"><source src=\"results/core_cpu_fp32/output_466305.v-qsvr-1.devcloud-edge.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoHTML('Intel Core CPU', \n",
    "          [f'results/core_cpu_fp32/output_{job_id_core_cpu_fp32[0]}.mp4'],f'results/core_cpu_fp32/stats_{job_id_core_cpu_fp32[0]}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View and assess performance results\n",
    "\n",
    "The running time of each inference task is recorded in `results/<device>/stats.txt`. Run the cell below to plot the results of all jobs side-by-side. Lower values mean better performance for **Inference Engine Processing Time** and higher values mean better performance for **Inference Engine FPS**. When comparing results, please keep in mind that some architectures are optimized for highest performance, others for low power or other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ceba9f451ef42fea1c19399a65bcd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"Benchmark results published by Intel or appearing on the Intel® DevCloud for the Edge website are …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8db29ce12b4f68868d9d978db298bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"Benchmark results published by Intel or appearing on the Intel® DevCloud for the Edge website are …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create table of <architecture>, <title> for plotting\n",
    "arch_list = [('core_cpu_fp32', 'intel-core,i5-6500te\\nCPU_FP32'),\n",
    "             ('core_cpu_int8', 'intel-core,i5-6500te\\nCPU_INT8'),\n",
    "             ('core_gpu_fp16', 'intel-core,i5-6500te\\nGPU_FP16'),\n",
    "             ('core_hddl_fp16', 'intel-core,i5-6500te\\nHDDL_FP16'),\n",
    "             ('core_multi_fp16', 'intel-core,i5-6500te\\nMULTI_FP16')]\n",
    "          \n",
    "# For each archtecture in table, create path to stats file or placeholder \n",
    "stats_list = []\n",
    "for arch, a_name in arch_list:\n",
    "    # if job_id_<architecture> exists, the job was run and has a stats file\n",
    "    if 'job_id_'+arch in vars():\n",
    "        stats_list.append((f'results/{arch}/stats_{vars()[\"job_id_\"+arch][0]}.txt', a_name))\n",
    "    else:\n",
    "        stats_list.append(('placeholder'+arch, a_name))\n",
    "\n",
    "# Plot the execution time from the stats files\n",
    "summaryPlot(stats_list, 'Architecture', 'Time, seconds', 'Inference Engine Processing Time', 'time')\n",
    "# Plot the frames per second from the stats files\n",
    "summaryPlot(stats_list, 'Architecture', 'Frames per second', 'Inference Engine FPS', 'fps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('results/core_cpu_fp32/stats_466299.v-qsvr-1.devcloud-edge.txt', 'intel-core,i5-6500te\\nCPU_FP32'), ('placeholdercore_cpu_INT8', 'intel-core,i5-6500te\\nCPU_INT8')]\n"
     ]
    }
   ],
   "source": [
    "print(stats_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telemetry Dashboard\n",
    "Once your submitted jobs are completed, run the cells below to view telemetry dashboards containing performance metrics for your model and target architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_t = \"<a target='_blank' href='{href}'> Click here to view telemetry dashboard of the last job ran on Intel® Core™ i5-6500TE</a>\"\n",
    "\n",
    "result_file = \"https://devcloud.intel.com/edge/metrics/d/\" + job_id_core[0].split('.')[0]\n",
    "\n",
    "html = HTML(link_t.format(href=result_file))\n",
    "\n",
    "display(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_t = \"<a target='_blank' href='{href}'> Click here to view metering dashboard of the last job ran on Intel® Xeon® Gold 6258R CPU</a>\"\n",
    "\n",
    "result_file = \"https://devcloud.intel.com/edge/metrics/d/\" + job_id_xeon_cascade_lake[0].split('.')[0]\n",
    "\n",
    "html = HTML(link_t.format(href=result_file))\n",
    "\n",
    "display(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_t = \"<a target='_blank' href='{href}'> Click here to view metering dashboard of the last job ran on Intel® Xeon® E3-1268L v5 CPU</a>\"\n",
    "\n",
    "result_file = \"https://devcloud.intel.com/edge/metrics/d/\" + job_id_xeon_skylake[0].split('.')[0]\n",
    "\n",
    "html = HTML(link_t.format(href=result_file))\n",
    "\n",
    "display(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_t = \"<a target='_blank' href='{href}'> Click here to view metering dashboard of the last job ran on Intel® Core CPU and using the onboard Intel® GPU</a>\"\n",
    "\n",
    "result_file = \"https://devcloud.intel.com/edge/metrics/d/\" + job_id_gpu[0].split('.')[0]\n",
    "\n",
    "html = HTML(link_t.format(href=result_file))\n",
    "\n",
    "display(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_t = \"<a target='_blank' href='{href}'> Click here to view metering dashboard of the last job ran on Intel® NCS 2 (Neural Compute Stick 2)</a>\"\n",
    "\n",
    "result_file = \"https://devcloud.intel.com/edge/metrics/d/\" + job_id_ncs2[0].split('.')[0]\n",
    "\n",
    "html = HTML(link_t.format(href=result_file))\n",
    "\n",
    "display(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_t = \"<a target='_blank' href='{href}'> Click here to view metering dashboard of the last job ran on UP Squared Grove IoT Development Kit (UP2)</a>\"\n",
    "\n",
    "result_file = \"https://devcloud.intel.com/edge/metrics/d/\" + job_id_atom[0].split('.')[0]\n",
    "\n",
    "html = HTML(link_t.format(href=result_file))\n",
    "\n",
    "display(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_t = \"<a target='_blank' href='{href}'> Click here to view metering dashboard of the last job ran on IEI Mustang-V100-MX8 ( Intel® Movidius™ Myriad™ X Vision Processing Unit (VPU))</a>\"\n",
    "\n",
    "result_file = \"https://devcloud.intel.com/edge/metrics/d/\" + job_id_hddlr[0].split('.')[0]\n",
    "html = HTML(link_t.format(href=result_file))\n",
    "display(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- [More Jupyter* Notebook Samples](https://devcloud.intel.com/edge/advanced/sample_applications/) - additional sample applications \n",
    "- [Jupyter* Notebook Tutorials](https://devcloud.intel.com/edge/get_started/tutorials) - sample application Jupyter* Notebook tutorials\n",
    "- [Intel® Distribution of OpenVINO™ toolkit Main Page](https://software.intel.com/openvino-toolkit) - learn more about the tools and use of the Intel® Distribution of OpenVINO™ toolkit for implementing inference on the edge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "For technical support, please see the [Intel® DevCloud Forums](https://software.intel.com/en-us/forums/intel-devcloud-for-edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=background-color:#0071C5;color:white;padding:0.5em;display:table-cell;width:100pc;vertical-align:middle>\n",
    "<img style=float:right src=\"https://devcloud.intel.com/edge/static/images/svg/IDZ_logo.svg\" alt=\"Intel DevCloud logo\" width=\"150px\"/>\n",
    "<a style=color:white>Intel® DevCloud for the Edge</a><br>   \n",
    "<a style=color:white href=\"#top\">Top of Page</a> | \n",
    "<a style=color:white href=\"https://devcloud.intel.com/edge/static/docs/terms/Intel-DevCloud-for-the-Edge-Usage-Agreement.pdf\">Usage Agreement (Intel)</a> | \n",
    "<a style=color:white href=\"https://devcloud.intel.com/edge/static/docs/terms/Colfax_Cloud_Service_Terms_v1.3.pdf\">Service Terms (Colfax)</a>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (OpenVINO 2022.1)",
   "language": "python",
   "name": "openvino_2022.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "675px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
