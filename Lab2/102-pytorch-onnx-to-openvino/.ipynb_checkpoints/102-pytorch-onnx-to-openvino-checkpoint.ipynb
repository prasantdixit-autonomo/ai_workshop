{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af86d01b",
   "metadata": {
    "id": "JwEAhQVzkAwA"
   },
   "source": [
    "# Convert a PyTorch Model to ONNX and OpenVINO IR\n",
    "\n",
    "This tutorial demonstrates step-by-step instructions to convert the PyTorch model to [ONNX](https://onnx.ai/) and OpenVINO Intermediate Representation (IR) formats. The model is pre-trained on the [CityScapes](https://www.cityscapes-dataset.com) dataset. The source of the model is [FastSeg](https://github.com/ekzhang/fastseg)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf8008",
   "metadata": {
    "id": "QB4Yo-rGGLmV"
   },
   "source": [
    "## Preparation\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ac8b138-9056-47cc-8ac5-b7bbdc5a29a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch==1.7\n",
      "  Downloading torch-1.7.0-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.8/776.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastseg in /home/intel/.local/lib/python3.8/site-packages (0.1.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.7) (3.7.4.3)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/intel/.local/lib/python3.8/site-packages (from torch==1.7) (1.19.5)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: torchvision>=0.6.0 in /home/intel/.local/lib/python3.8/site-packages (from fastseg) (0.12.0)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /home/intel/.local/lib/python3.8/site-packages (from fastseg) (9.1.1)\n",
      "Requirement already satisfied: geffnet>=0.9.8 in /home/intel/.local/lib/python3.8/site-packages (from fastseg) (1.0.2)\n",
      "Collecting torchvision>=0.6.0\n",
      "  Downloading torchvision-0.11.3-cp38-cp38-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading torchvision-0.11.2-cp38-cp38-manylinux1_x86_64.whl (23.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading torchvision-0.11.1-cp38-cp38-manylinux1_x86_64.whl (23.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading torchvision-0.10.1-cp38-cp38-manylinux1_x86_64.whl (22.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.1/22.1 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading torchvision-0.10.0-cp38-cp38-manylinux1_x86_64.whl (22.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.1/22.1 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading torchvision-0.9.1-cp38-cp38-manylinux1_x86_64.whl (17.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading torchvision-0.9.0-cp38-cp38-manylinux1_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading torchvision-0.8.2-cp38-cp38-manylinux1_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading torchvision-0.8.1-cp38-cp38-manylinux1_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=50838aa45e4c7d9f50a39ee8a634f7198872eb1246ac68f4e85aa42148883860\n",
      "  Stored in directory: /home/intel/.cache/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built future\n",
      "Installing collected packages: dataclasses, future, torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0\n",
      "    Uninstalling torchvision-0.12.0:\n",
      "      Successfully uninstalled torchvision-0.12.0\n",
      "Successfully installed dataclasses-0.6 future-0.18.2 torch-1.7.0 torchvision-0.8.1\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.7.1 fastseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2573d828",
   "metadata": {
    "id": "2ynWRum4iiTz"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Markdown, display\n",
    "from fastseg import MobileV3Large\n",
    "from openvino.runtime import Core\n",
    "\n",
    "sys.path.append(\"utils\")\n",
    "from notebook_utils import CityScapesSegmentation, segmentation_map_to_image, viz_result_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b80fe4",
   "metadata": {},
   "source": [
    "### Settings\n",
    "\n",
    "Set the name for the model, and the image width and height that will be used for the network. CityScapes is pretrained on images of 2048x1024. Using smaller dimensions will impact model accuracy, but will improve inference speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a9303a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 1024  # Suggested values: 2048, 1024 or 512. The minimum width is 512.\n",
    "# Set IMAGE_HEIGHT manually for custom input sizes. Minimum height is 512\n",
    "IMAGE_HEIGHT = 1024 if IMAGE_WIDTH == 2048 else 512\n",
    "DIRECTORY_NAME = \"model\"\n",
    "BASE_MODEL_NAME = DIRECTORY_NAME + f\"/fastseg{IMAGE_WIDTH}\"\n",
    "\n",
    "# Paths where PyTorch, ONNX and OpenVINO IR models will be stored\n",
    "model_path = Path(BASE_MODEL_NAME).with_suffix(\".pth\")\n",
    "onnx_path = model_path.with_suffix(\".onnx\")\n",
    "ir_path = model_path.with_suffix(\".xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b33033e",
   "metadata": {
    "id": "u5xKw0hR0jq6"
   },
   "source": [
    "### Download the Fastseg Model\n",
    "\n",
    "Download, load and save the model with pretrained weights. This may take some time if you have not downloaded the model before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9600481",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGKkMRfvi0op",
    "outputId": "4eb1f9af-a4c5-424c-f808-dd9cc2600975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the Fastseg model (if it has not been downloaded before)....\n",
      "Loading pretrained model mobilev3large-lraspp with F=128...\n",
      "Loaded PyTorch Fastseg model\n",
      "Model saved at model/fastseg1024.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading the Fastseg model (if it has not been downloaded before)....\")\n",
    "model = MobileV3Large.from_pretrained().cpu().eval()\n",
    "print(\"Loaded PyTorch Fastseg model\")\n",
    "\n",
    "# Save the model\n",
    "model_path.parent.mkdir(exist_ok=True)\n",
    "torch.save(model.state_dict(), str(model_path))\n",
    "print(f\"Model saved at {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad92bb9",
   "metadata": {
    "id": "Rhc_7EObUypw"
   },
   "source": [
    "## ONNX Model Conversion\n",
    "\n",
    "### Convert PyTorch model to ONNX\n",
    "\n",
    "The output for this cell will show some warnings. These are most likely harmless. Conversion succeeded if the last line of the output says `ONNX model exported to fastseg1024.onnx.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "659aeac7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipQWpbgQUxoo",
    "outputId": "bbc1734a-c2a2-4261-ed45-264b9e3edd00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ONNX export failed: Couldn't export Python operator HardSwishJitAutoFn\n\nDefined at:\n/home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py(174): forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/container.py(141): forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/intel/.local/lib/python3.8/site-packages/fastseg/model/mobilenetv3.py(48): forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py(78): forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/intel/.local/lib/python3.8/site-packages/torch/jit/_trace.py(118): wrapper\n/home/intel/.local/lib/python3.8/site-packages/torch/jit/_trace.py(127): forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/intel/.local/lib/python3.8/site-packages/torch/jit/_trace.py(1166): _get_trace_graph\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py(391): _trace_and_get_graph_from_model\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py(440): _create_jit_graph\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py(499): _model_to_graph\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py(719): _export\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py(118): export\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/__init__.py(305): export\n/tmp/ipykernel_4200/40378742.py(6): <cell line: 1>\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3398): run_code\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3338): run_ast_nodes\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3135): run_cell_async\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2936): _run_cell\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2881): run_cell\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py(528): run_cell\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py(383): do_execute\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(728): execute_request\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(404): dispatch_shell\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(497): process_one\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(508): dispatch_queue\n/usr/lib/python3.8/asyncio/events.py(81): _run\n/usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n/usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n/home/intel/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py(199): start\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py(712): start\n/home/intel/.local/lib/python3.8/site-packages/traitlets/config/application.py(976): launch_instance\n/home/intel/.local/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n/usr/lib/python3.8/runpy.py(87): _run_code\n/usr/lib/python3.8/runpy.py(194): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%x.1 : Float(1, 3, 512, 1024, strides=[1572864, 524288, 1024, 1], requires_grad=0, device=cpu),\n      %trunk.block2.0.se.conv_reduce.weight : Float(24, 72, 1, 1, strides=[72, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.0.se.conv_reduce.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block2.0.se.conv_expand.weight : Float(72, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.0.se.conv_expand.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block2.1.se.conv_reduce.weight : Float(32, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.1.se.conv_reduce.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block2.1.se.conv_expand.weight : Float(120, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.1.se.conv_expand.bias : Float(120, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block2.2.se.conv_reduce.weight : Float(32, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.2.se.conv_reduce.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block2.2.se.conv_expand.weight : Float(120, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.2.se.conv_expand.bias : Float(120, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block4.0.se.conv_reduce.weight : Float(120, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block4.0.se.conv_reduce.bias : Float(120, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block4.0.se.conv_expand.weight : Float(480, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block4.0.se.conv_expand.bias : Float(480, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block4.1.se.conv_reduce.weight : Float(168, 672, 1, 1, strides=[672, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block4.1.se.conv_reduce.bias : Float(168, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block4.1.se.conv_expand.weight : Float(672, 168, 1, 1, strides=[168, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block4.1.se.conv_expand.bias : Float(672, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.0.se.conv_reduce.weight : Float(168, 672, 1, 1, strides=[672, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.0.se.conv_reduce.bias : Float(168, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.0.se.conv_expand.weight : Float(672, 168, 1, 1, strides=[168, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.0.se.conv_expand.bias : Float(672, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.1.se.conv_reduce.weight : Float(240, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.1.se.conv_reduce.bias : Float(240, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.1.se.conv_expand.weight : Float(960, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.1.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.2.se.conv_reduce.weight : Float(240, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.2.se.conv_reduce.bias : Float(240, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.2.se.conv_expand.weight : Float(960, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.2.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cpu),\n      %aspp_conv2.1.weight : Float(128, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cpu),\n      %convs2.weight : Float(32, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cpu),\n      %convs4.weight : Float(64, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=1, device=cpu),\n      %conv_up1.weight : Float(128, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=1, device=cpu),\n      %conv_up1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n      %last.weight : Float(19, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=1, device=cpu),\n      %last.bias : Float(19, strides=[1], requires_grad=1, device=cpu),\n      %onnx::Conv_958 : Float(16, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_959 : Float(16, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_961 : Float(16, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_962 : Float(16, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_964 : Float(16, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_965 : Float(16, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_967 : Float(64, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_968 : Float(64, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_970 : Float(64, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_971 : Float(64, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_973 : Float(24, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_974 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_976 : Float(72, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_977 : Float(72, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_979 : Float(72, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_980 : Float(72, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_982 : Float(24, 72, 1, 1, strides=[72, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_983 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_985 : Float(72, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_986 : Float(72, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_988 : Float(72, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_989 : Float(72, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_991 : Float(40, 72, 1, 1, strides=[72, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_992 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_994 : Float(120, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_995 : Float(120, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_997 : Float(120, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_998 : Float(120, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1000 : Float(40, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1001 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1003 : Float(120, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1004 : Float(120, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1006 : Float(120, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1007 : Float(120, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1009 : Float(40, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1010 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1012 : Float(240, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1013 : Float(240, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1015 : Float(240, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1016 : Float(240, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1018 : Float(80, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1019 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1021 : Float(200, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1022 : Float(200, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1024 : Float(200, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1025 : Float(200, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1027 : Float(80, 200, 1, 1, strides=[200, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1028 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1030 : Float(184, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1031 : Float(184, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1033 : Float(184, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1034 : Float(184, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1036 : Float(80, 184, 1, 1, strides=[184, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1037 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1039 : Float(184, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1040 : Float(184, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1042 : Float(184, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1043 : Float(184, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1045 : Float(80, 184, 1, 1, strides=[184, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1046 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1048 : Float(480, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1049 : Float(480, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1051 : Float(480, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1052 : Float(480, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1054 : Float(112, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1055 : Float(112, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1057 : Float(672, 112, 1, 1, strides=[112, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1058 : Float(672, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1060 : Float(672, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1061 : Float(672, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1063 : Float(112, 672, 1, 1, strides=[672, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1064 : Float(112, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1066 : Float(672, 112, 1, 1, strides=[112, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1067 : Float(672, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1069 : Float(672, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1070 : Float(672, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1072 : Float(160, 672, 1, 1, strides=[672, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1073 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1075 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1076 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1078 : Float(960, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1079 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1081 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1082 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1084 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1085 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1087 : Float(960, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1088 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1090 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1091 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1093 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1094 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1096 : Float(128, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1097 : Float(128, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1099 : Float(128, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1100 : Float(128, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1102 : Float(128, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1103 : Float(128, strides=[1], requires_grad=0, device=cpu)):\n  %onnx::Unsqueeze_334 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_335 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Unsqueeze_336 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_337 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Concat_338 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_334)\n  %onnx::Concat_339 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_335)\n  %onnx::Concat_340 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_336)\n  %onnx::Concat_341 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_337)\n  %onnx::Shape_342 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_338, %onnx::Concat_339, %onnx::Concat_340, %onnx::Concat_341) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_343 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_334)\n  %onnx::Concat_344 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_335)\n  %onnx::Concat_345 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_336)\n  %onnx::Concat_346 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_337)\n  %onnx::Cast_347 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_343, %onnx::Concat_344, %onnx::Concat_345, %onnx::Concat_346) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_348 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_349 : Long(1, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_342) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_350 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%onnx::Gather_349, %onnx::Gather_348) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_351 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_352 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_353 : Long(device=cpu) = onnx::Mul(%onnx::Mul_351, %onnx::Mul_352) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::ConstantOfShape_354 : Long(1, strides=[1], device=cpu) = onnx::Sub(%onnx::Sub_353, %onnx::Sub_350) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_355 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_347) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_356 : Long(4, device=cpu) = onnx::ConstantOfShape[value={0}](%onnx::ConstantOfShape_354) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_357 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_355, %onnx::Concat_356) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_358 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_359 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape(%onnx::Reshape_357, %onnx::Reshape_358) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_360 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_361 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_362 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_363 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Transpose_364 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice(%onnx::Slice_359, %onnx::Slice_361, %onnx::Slice_362, %onnx::Slice_360, %onnx::Slice_363) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_365 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%onnx::Transpose_364) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_366 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Cast_367 : Long(8, strides=[1], device=cpu) = onnx::Reshape(%onnx::Reshape_365, %onnx::Reshape_366) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_368 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_367) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_369 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Conv_370 : Float(*, *, *, *, strides=[1577475, 525825, 1025, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\"](%x.1, %onnx::Pad_368, %onnx::Pad_369) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %x : Float(*, 16, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%onnx::Conv_370, %onnx::Conv_958, %onnx::Conv_959) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:72:0\n  %input.3 : Float(*, *, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.8 : Float(*, *, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=16, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input.3, %onnx::Conv_961, %onnx::Conv_962) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_376 : Float(*, *, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.8) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Add_963 : Float(*, *, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_376, %onnx::Conv_964, %onnx::Conv_965) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_379 : Float(*, *, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_963, %input.3) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:186:0\n  %input.20 : Float(*, *, *, *, strides=[8388608, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_379, %onnx::Conv_967, %onnx::Conv_968) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Shape_382 : Float(*, *, *, *, strides=[8388608, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.20) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Gather_383 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_382) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_384 : Long(device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_385 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_383, %onnx::Gather_384) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_386 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_382) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_387 : Long(device=cpu) = onnx::Constant[value={3}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_388 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_386, %onnx::Gather_387) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_389 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_390 : Long(device=cpu) = onnx::Div(%onnx::Div_385, %onnx::Div_389) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_391 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_390) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Neg_392 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_391) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_393 : Long(requires_grad=0, device=cpu) = onnx::Neg(%onnx::Neg_392) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Sub_394 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Mul_395 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_393, %onnx::Sub_394) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Mul_396 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %onnx::Add_397 : Long(requires_grad=0, device=cpu) = onnx::Mul(%onnx::Mul_395, %onnx::Mul_396) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_398 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_399 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_397, %onnx::Add_398) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_400 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Sub_401 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_399, %onnx::Add_400) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_402 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_401, %onnx::Div_385) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_403 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_404 : Long(device=cpu) = onnx::Div(%onnx::Div_388, %onnx::Div_403) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_405 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_404) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Neg_406 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_405) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_407 : Long(requires_grad=0, device=cpu) = onnx::Neg(%onnx::Neg_406) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Sub_408 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Mul_409 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_407, %onnx::Sub_408) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Mul_410 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %onnx::Add_411 : Long(requires_grad=0, device=cpu) = onnx::Mul(%onnx::Mul_409, %onnx::Mul_410) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_412 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_413 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_411, %onnx::Add_412) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_414 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Sub_415 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_413, %onnx::Add_414) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_416 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_415, %onnx::Div_388) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_417 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_418 : Long(device=cpu) = onnx::Div(%onnx::Div_416, %onnx::Div_417) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_419 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_418) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_420 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_419) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Div_421 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_422 : Long(device=cpu) = onnx::Div(%onnx::Div_416, %onnx::Div_421) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_423 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_422) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_424 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_423) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_425 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Div_416, %onnx::Sub_424) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Div_426 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_427 : Long(device=cpu) = onnx::Div(%onnx::Div_402, %onnx::Div_426) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_428 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_427) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_429 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_428) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Div_430 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_431 : Long(device=cpu) = onnx::Div(%onnx::Div_402, %onnx::Div_430) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_432 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_431) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_433 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_432) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_434 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Div_402, %onnx::Sub_433) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Concat_435 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_420)\n  %onnx::Concat_436 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_425)\n  %onnx::Concat_437 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_429)\n  %onnx::Concat_438 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_434)\n  %onnx::Shape_439 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_435, %onnx::Concat_436, %onnx::Concat_437, %onnx::Concat_438) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_440 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_420)\n  %onnx::Concat_441 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_425)\n  %onnx::Concat_442 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_429)\n  %onnx::Concat_443 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_434)\n  %onnx::Cast_444 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_440, %onnx::Concat_441, %onnx::Concat_442, %onnx::Concat_443) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_445 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_446 : Long(1, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_439) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_447 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%onnx::Gather_446, %onnx::Gather_445) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_448 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_449 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_450 : Long(device=cpu) = onnx::Mul(%onnx::Mul_448, %onnx::Mul_449) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::ConstantOfShape_451 : Long(1, strides=[1], device=cpu) = onnx::Sub(%onnx::Sub_450, %onnx::Sub_447) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_452 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_444) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_453 : Long(4, device=cpu) = onnx::ConstantOfShape[value={0}](%onnx::ConstantOfShape_451) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_454 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_452, %onnx::Concat_453) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_455 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_456 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape(%onnx::Reshape_454, %onnx::Reshape_455) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_457 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_458 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_459 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_460 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Transpose_461 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice(%onnx::Slice_456, %onnx::Slice_458, %onnx::Slice_459, %onnx::Slice_457, %onnx::Slice_460) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_462 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%onnx::Transpose_461) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Cast_464 : Long(8, strides=[1], device=cpu) = onnx::Reshape(%onnx::Reshape_462, %onnx::Reshape_463) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_465 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_464) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_466 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Conv_467 : Float(*, *, *, *, strides=[8437824, 131841, 513, 1], requires_grad=1, device=cpu) = onnx::Pad[mode=\"constant\"](%onnx::Shape_382, %onnx::Pad_465, %onnx::Pad_466) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %input.28 : Float(*, *, *, *, strides=[2097152, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=64, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%onnx::Conv_467, %onnx::Conv_970, %onnx::Conv_971) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:72:0\n  %onnx::Conv_470 : Float(*, *, *, *, strides=[2097152, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.28) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.36 : Float(*, *, *, *, strides=[786432, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_470, %onnx::Conv_973, %onnx::Conv_974) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.44 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.36, %onnx::Conv_976, %onnx::Conv_977) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_475 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.44) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.52 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=72, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%onnx::Conv_475, %onnx::Conv_979, %onnx::Conv_980) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_478 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.52) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Add_981 : Float(*, *, *, *, strides=[786432, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_478, %onnx::Conv_982, %onnx::Conv_983) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_481 : Float(*, *, *, *, strides=[786432, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_981, %input.36) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %input.64 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_481, %onnx::Conv_985, %onnx::Conv_986) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Shape_484 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.64) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Gather_485 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_484) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_486 : Long(device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_487 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_485, %onnx::Gather_486) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_488 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_484) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_489 : Long(device=cpu) = onnx::Constant[value={3}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_490 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_488, %onnx::Gather_489) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_491 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_492 : Long(device=cpu) = onnx::Div(%onnx::Div_487, %onnx::Div_491) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_493 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_492) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Neg_494 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_493) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_495 : Long(requires_grad=0, device=cpu) = onnx::Neg(%onnx::Neg_494) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Sub_496 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Mul_497 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_495, %onnx::Sub_496) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Mul_498 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %onnx::Add_499 : Long(requires_grad=0, device=cpu) = onnx::Mul(%onnx::Mul_497, %onnx::Mul_498) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_500 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_501 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_499, %onnx::Add_500) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_502 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Sub_503 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_501, %onnx::Add_502) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_504 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_503, %onnx::Div_487) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_505 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_506 : Long(device=cpu) = onnx::Div(%onnx::Div_490, %onnx::Div_505) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_507 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_506) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Neg_508 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_507) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_509 : Long(requires_grad=0, device=cpu) = onnx::Neg(%onnx::Neg_508) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Sub_510 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Mul_511 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_509, %onnx::Sub_510) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Mul_512 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %onnx::Add_513 : Long(requires_grad=0, device=cpu) = onnx::Mul(%onnx::Mul_511, %onnx::Mul_512) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_514 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_515 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_513, %onnx::Add_514) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_516 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Sub_517 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_515, %onnx::Add_516) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_518 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_517, %onnx::Div_490) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_519 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_520 : Long(device=cpu) = onnx::Div(%onnx::Div_518, %onnx::Div_519) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_521 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_520) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_522 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_521) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Div_523 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_524 : Long(device=cpu) = onnx::Div(%onnx::Div_518, %onnx::Div_523) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_525 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_524) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_526 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_525) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_527 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Div_518, %onnx::Sub_526) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Div_528 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_529 : Long(device=cpu) = onnx::Div(%onnx::Div_504, %onnx::Div_528) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_530 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_529) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_531 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_530) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Div_532 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_533 : Long(device=cpu) = onnx::Div(%onnx::Div_504, %onnx::Div_532) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_534 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_533) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_535 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_534) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_536 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Div_504, %onnx::Sub_535) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Concat_537 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_522)\n  %onnx::Concat_538 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_527)\n  %onnx::Concat_539 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_531)\n  %onnx::Concat_540 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_536)\n  %onnx::Shape_541 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_537, %onnx::Concat_538, %onnx::Concat_539, %onnx::Concat_540) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_542 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_522)\n  %onnx::Concat_543 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_527)\n  %onnx::Concat_544 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_531)\n  %onnx::Concat_545 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_536)\n  %onnx::Cast_546 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_542, %onnx::Concat_543, %onnx::Concat_544, %onnx::Concat_545) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_547 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_548 : Long(1, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_541) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_549 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%onnx::Gather_548, %onnx::Gather_547) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_550 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_551 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_552 : Long(device=cpu) = onnx::Mul(%onnx::Mul_550, %onnx::Mul_551) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::ConstantOfShape_553 : Long(1, strides=[1], device=cpu) = onnx::Sub(%onnx::Sub_552, %onnx::Sub_549) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_554 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_546) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_555 : Long(4, device=cpu) = onnx::ConstantOfShape[value={0}](%onnx::ConstantOfShape_553) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_556 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_554, %onnx::Concat_555) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_557 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_558 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape(%onnx::Reshape_556, %onnx::Reshape_557) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_559 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_560 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_561 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_562 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Transpose_563 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice(%onnx::Slice_558, %onnx::Slice_560, %onnx::Slice_561, %onnx::Slice_559, %onnx::Slice_562) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_564 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%onnx::Transpose_563) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_565 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Cast_566 : Long(8, strides=[1], device=cpu) = onnx::Reshape(%onnx::Reshape_564, %onnx::Reshape_565) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_567 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_566) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_568 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Conv_569 : Float(*, *, *, *, strides=[2442888, 33929, 259, 1], requires_grad=1, device=cpu) = onnx::Pad[mode=\"constant\"](%onnx::Shape_484, %onnx::Pad_567, %onnx::Pad_568) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %input.72 : Float(*, *, *, *, strides=[589824, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=72, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[2, 2]](%onnx::Conv_569, %onnx::Conv_988, %onnx::Conv_989) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:72:0\n  %onnx::ReduceMean_572 : Float(*, *, *, *, strides=[589824, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.72) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.76 : Float(*, *, *, *, strides=[72, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_572) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.80 : Float(*, *, *, *, strides=[24, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.76, %trunk.block2.0.se.conv_reduce.weight, %trunk.block2.0.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_575 : Float(*, *, *, *, strides=[24, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.80) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se : Float(*, *, *, *, strides=[72, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_575, %trunk.block2.0.se.conv_expand.weight, %trunk.block2.0.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_577 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_578 : Float(*, *, *, *, strides=[72, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se, %onnx::Add_577) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_579 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_578) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_580 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_581 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_582 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_580) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_583 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_581) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_584 : Float(*, *, *, *, strides=[72, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_579, %onnx::Clip_582, %onnx::Clip_583) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_585 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_586 : Float(*, *, *, *, strides=[72, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_584, %onnx::Div_585) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.84 : Float(*, *, *, *, strides=[589824, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_572, %onnx::Mul_586) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %input.92 : Float(*, *, *, *, strides=[327680, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.84, %onnx::Conv_991, %onnx::Conv_992) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.100 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.92, %onnx::Conv_994, %onnx::Conv_995) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_592 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.100) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.108 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=120, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%onnx::Conv_592, %onnx::Conv_997, %onnx::Conv_998) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_595 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.108) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.112 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_595) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.116 : Float(*, *, *, *, strides=[32, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.112, %trunk.block2.1.se.conv_reduce.weight, %trunk.block2.1.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_598 : Float(*, *, *, *, strides=[32, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.116) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.3 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_598, %trunk.block2.1.se.conv_expand.weight, %trunk.block2.1.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_600 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_601 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.3, %onnx::Add_600) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_602 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_601) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_603 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_604 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_605 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_603) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_606 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_604) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_607 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_602, %onnx::Clip_605, %onnx::Clip_606) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_608 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_609 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_607, %onnx::Div_608) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.120 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_595, %onnx::Mul_609) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %onnx::Add_999 : Float(*, *, *, *, strides=[327680, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.120, %onnx::Conv_1000, %onnx::Conv_1001) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_613 : Float(*, *, *, *, strides=[327680, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_999, %input.92) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %input.132 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_613, %onnx::Conv_1003, %onnx::Conv_1004) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_616 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.132) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.140 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=120, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%onnx::Conv_616, %onnx::Conv_1006, %onnx::Conv_1007) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_619 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.140) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.144 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_619) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.148 : Float(*, *, *, *, strides=[32, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.144, %trunk.block2.2.se.conv_reduce.weight, %trunk.block2.2.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_622 : Float(*, *, *, *, strides=[32, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.148) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.7 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_622, %trunk.block2.2.se.conv_expand.weight, %trunk.block2.2.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_624 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_625 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.7, %onnx::Add_624) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_626 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_625) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_627 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_628 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_629 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_627) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_630 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_628) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_631 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_626, %onnx::Clip_629, %onnx::Clip_630) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_632 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_633 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_631, %onnx::Div_632) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.152 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_619, %onnx::Mul_633) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %onnx::Add_1008 : Float(*, *, *, *, strides=[327680, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.152, %onnx::Conv_1009, %onnx::Conv_1010) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_637 : Float(*, *, *, *, strides=[327680, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1008, %onnx::Conv_613) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.4 : Float(*, *, *, *, strides=[1966080, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_637, %onnx::Conv_1012, %onnx::Conv_1013) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %x.11 : Float(*, *, *, *, strides=[1966080, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.4) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %onnx::Unsqueeze_641 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_642 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Unsqueeze_643 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_644 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Concat_645 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_641)\n  %onnx::Concat_646 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_642)\n  %onnx::Concat_647 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_643)\n  %onnx::Concat_648 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_644)\n  %onnx::Shape_649 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_645, %onnx::Concat_646, %onnx::Concat_647, %onnx::Concat_648) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_650 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_641)\n  %onnx::Concat_651 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_642)\n  %onnx::Concat_652 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_643)\n  %onnx::Concat_653 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_644)\n  %onnx::Cast_654 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_650, %onnx::Concat_651, %onnx::Concat_652, %onnx::Concat_653) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_655 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_656 : Long(1, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_649) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_657 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%onnx::Gather_656, %onnx::Gather_655) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_658 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_659 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_660 : Long(device=cpu) = onnx::Mul(%onnx::Mul_658, %onnx::Mul_659) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::ConstantOfShape_661 : Long(1, strides=[1], device=cpu) = onnx::Sub(%onnx::Sub_660, %onnx::Sub_657) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_662 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_654) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_663 : Long(4, device=cpu) = onnx::ConstantOfShape[value={0}](%onnx::ConstantOfShape_661) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_664 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_662, %onnx::Concat_663) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_665 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_666 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape(%onnx::Reshape_664, %onnx::Reshape_665) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_667 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_668 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_669 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_670 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Transpose_671 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice(%onnx::Slice_666, %onnx::Slice_668, %onnx::Slice_669, %onnx::Slice_667, %onnx::Slice_670) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_672 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%onnx::Transpose_671) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_673 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Cast_674 : Long(8, strides=[1], device=cpu) = onnx::Reshape(%onnx::Reshape_672, %onnx::Reshape_673) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_675 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_674) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_676 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Conv_677 : Float(*, *, *, *, strides=[2154240, 8976, 132, 1], requires_grad=1, device=cpu) = onnx::Pad[mode=\"constant\"](%x.11, %onnx::Pad_675, %onnx::Pad_676) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %x.8 : Float(*, *, *, *, strides=[1966080, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=240, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_677, %onnx::Conv_1015, %onnx::Conv_1016) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:72:0\n  %input.113 : Float(*, *, *, *, strides=[1966080, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.8) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.172 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.113, %onnx::Conv_1018, %onnx::Conv_1019) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %x.12 : Float(*, *, *, *, strides=[1638400, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.172, %onnx::Conv_1021, %onnx::Conv_1022) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.121 : Float(*, *, *, *, strides=[1638400, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.12) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.16 : Float(*, *, *, *, strides=[1638400, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=200, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%input.121, %onnx::Conv_1024, %onnx::Conv_1025) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.125 : Float(*, *, *, *, strides=[1638400, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.16) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %onnx::Add_1026 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.125, %onnx::Conv_1027, %onnx::Conv_1028) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_691 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1026, %input.172) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.20 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_691, %onnx::Conv_1030, %onnx::Conv_1031) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.133 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.20) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.24 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=184, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%input.133, %onnx::Conv_1033, %onnx::Conv_1034) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.137 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.24) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %onnx::Add_1035 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.137, %onnx::Conv_1036, %onnx::Conv_1037) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_700 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1035, %onnx::Conv_691) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.28 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_700, %onnx::Conv_1039, %onnx::Conv_1040) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.145 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.28) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.32 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=184, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%input.145, %onnx::Conv_1042, %onnx::Conv_1043) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.149 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.32) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %onnx::Add_1044 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.149, %onnx::Conv_1045, %onnx::Conv_1046) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_709 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1044, %onnx::Conv_700) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.36 : Float(*, *, *, *, strides=[3932160, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_709, %onnx::Conv_1048, %onnx::Conv_1049) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.157 : Float(*, *, *, *, strides=[3932160, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.36) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.40 : Float(*, *, *, *, strides=[3932160, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=480, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%input.157, %onnx::Conv_1051, %onnx::Conv_1052) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_715 : Float(*, *, *, *, strides=[3932160, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.40) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.220 : Float(*, *, *, *, strides=[480, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_715) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.224 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.220, %trunk.block4.0.se.conv_reduce.weight, %trunk.block4.0.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_718 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.224) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.11 : Float(*, *, *, *, strides=[480, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_718, %trunk.block4.0.se.conv_expand.weight, %trunk.block4.0.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_720 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_721 : Float(*, *, *, *, strides=[480, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.11, %onnx::Add_720) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_722 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_721) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_723 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_724 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_725 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_723) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_726 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_724) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_727 : Float(*, *, *, *, strides=[480, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_722, %onnx::Clip_725, %onnx::Clip_726) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_728 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_729 : Float(*, *, *, *, strides=[480, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_727, %onnx::Div_728) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.228 : Float(*, *, *, *, strides=[3932160, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_715, %onnx::Mul_729) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %input.236 : Float(*, *, *, *, strides=[917504, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.228, %onnx::Conv_1054, %onnx::Conv_1055) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %x.44 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.236, %onnx::Conv_1057, %onnx::Conv_1058) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.175 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.44) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.48 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=672, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%input.175, %onnx::Conv_1060, %onnx::Conv_1061) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_738 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.48) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.248 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_738) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.252 : Float(*, *, *, *, strides=[168, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.248, %trunk.block4.1.se.conv_reduce.weight, %trunk.block4.1.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_741 : Float(*, *, *, *, strides=[168, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.252) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.15 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_741, %trunk.block4.1.se.conv_expand.weight, %trunk.block4.1.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_743 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_744 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.15, %onnx::Add_743) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_745 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_744) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_746 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_747 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_748 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_746) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_749 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_747) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_750 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_745, %onnx::Clip_748, %onnx::Clip_749) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_751 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_752 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_750, %onnx::Div_751) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.256 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_738, %onnx::Mul_752) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %onnx::Add_1062 : Float(*, *, *, *, strides=[917504, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.256, %onnx::Conv_1063, %onnx::Conv_1064) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_756 : Float(*, *, *, *, strides=[917504, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1062, %input.236) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.52 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_756, %onnx::Conv_1066, %onnx::Conv_1067) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %x.37 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.52) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %onnx::Unsqueeze_760 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_761 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Unsqueeze_762 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_763 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Concat_764 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_760)\n  %onnx::Concat_765 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_761)\n  %onnx::Concat_766 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_762)\n  %onnx::Concat_767 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_763)\n  %onnx::Shape_768 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_764, %onnx::Concat_765, %onnx::Concat_766, %onnx::Concat_767) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_769 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_760)\n  %onnx::Concat_770 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_761)\n  %onnx::Concat_771 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_762)\n  %onnx::Concat_772 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_763)\n  %onnx::Cast_773 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_769, %onnx::Concat_770, %onnx::Concat_771, %onnx::Concat_772) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_774 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_775 : Long(1, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_768) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_776 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%onnx::Gather_775, %onnx::Gather_774) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_777 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_778 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_779 : Long(device=cpu) = onnx::Mul(%onnx::Mul_777, %onnx::Mul_778) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::ConstantOfShape_780 : Long(1, strides=[1], device=cpu) = onnx::Sub(%onnx::Sub_779, %onnx::Sub_776) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_781 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_773) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_782 : Long(4, device=cpu) = onnx::ConstantOfShape[value={0}](%onnx::ConstantOfShape_780) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_783 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_781, %onnx::Concat_782) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_784 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_785 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape(%onnx::Reshape_783, %onnx::Reshape_784) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_786 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_787 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_788 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_789 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Transpose_790 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice(%onnx::Slice_785, %onnx::Slice_787, %onnx::Slice_788, %onnx::Slice_786, %onnx::Slice_789) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_791 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%onnx::Transpose_790) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_792 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Cast_793 : Long(8, strides=[1], device=cpu) = onnx::Reshape(%onnx::Reshape_791, %onnx::Reshape_792) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_794 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_793) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_795 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Conv_796 : Float(*, *, *, *, strides=[7741440, 11520, 144, 1], requires_grad=1, device=cpu) = onnx::Pad[mode=\"constant\"](%x.37, %onnx::Pad_794, %onnx::Pad_795) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %x.56 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[4, 4], group=672, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_796, %onnx::Conv_1069, %onnx::Conv_1070) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:72:0\n  %onnx::ReduceMean_799 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.56) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.272 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_799) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.276 : Float(*, *, *, *, strides=[168, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.272, %trunk.block5.0.se.conv_reduce.weight, %trunk.block5.0.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_802 : Float(*, *, *, *, strides=[168, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.276) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.19 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_802, %trunk.block5.0.se.conv_expand.weight, %trunk.block5.0.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_804 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_805 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.19, %onnx::Add_804) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_806 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_805) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_807 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_808 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_809 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_807) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_810 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_808) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_811 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_806, %onnx::Clip_809, %onnx::Clip_810) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_812 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_813 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_811, %onnx::Div_812) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.280 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_799, %onnx::Mul_813) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %input.288 : Float(*, *, *, *, strides=[1310720, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.280, %onnx::Conv_1072, %onnx::Conv_1073) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %x.60 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.288, %onnx::Conv_1075, %onnx::Conv_1076) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.209 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.60) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.64 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[4, 4], group=960, kernel_shape=[5, 5], pads=[8, 8, 8, 8], strides=[1, 1]](%input.209, %onnx::Conv_1078, %onnx::Conv_1079) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_822 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.64) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.300 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_822) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.304 : Float(*, *, *, *, strides=[240, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.300, %trunk.block5.1.se.conv_reduce.weight, %trunk.block5.1.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_825 : Float(*, *, *, *, strides=[240, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.304) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.23 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_825, %trunk.block5.1.se.conv_expand.weight, %trunk.block5.1.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_827 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_828 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.23, %onnx::Add_827) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_829 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_828) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_830 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_831 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_832 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_830) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_833 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_831) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_834 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_829, %onnx::Clip_832, %onnx::Clip_833) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_835 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_836 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_834, %onnx::Div_835) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.308 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_822, %onnx::Mul_836) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %onnx::Add_1080 : Float(*, *, *, *, strides=[1310720, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.308, %onnx::Conv_1081, %onnx::Conv_1082) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_840 : Float(*, *, *, *, strides=[1310720, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1080, %input.288) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.68 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_840, %onnx::Conv_1084, %onnx::Conv_1085) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.227 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.68) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.72 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[4, 4], group=960, kernel_shape=[5, 5], pads=[8, 8, 8, 8], strides=[1, 1]](%input.227, %onnx::Conv_1087, %onnx::Conv_1088) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_846 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.72) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.324 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_846) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.328 : Float(*, *, *, *, strides=[240, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.324, %trunk.block5.2.se.conv_reduce.weight, %trunk.block5.2.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_849 : Float(*, *, *, *, strides=[240, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.328) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.27 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_849, %trunk.block5.2.se.conv_expand.weight, %trunk.block5.2.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_851 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_852 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.27, %onnx::Add_851) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_853 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_852) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_854 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_855 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_856 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_854) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_857 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_855) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_858 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_853, %onnx::Clip_856, %onnx::Clip_857) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_859 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_860 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_858, %onnx::Div_859) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.332 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_846, %onnx::Mul_860) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %onnx::Add_1089 : Float(*, *, *, *, strides=[1310720, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.332, %onnx::Conv_1090, %onnx::Conv_1091) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_864 : Float(*, *, *, *, strides=[1310720, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1089, %onnx::Conv_840) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.76 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[4, 4], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_864, %onnx::Conv_1093, %onnx::Conv_1094) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.245 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.76) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.348 : Float(*, *, *, *, strides=[1048576, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.245, %onnx::Conv_1096, %onnx::Conv_1097) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Mul_870 : Float(*, *, *, *, strides=[1048576, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.348) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Pad_871 : Long(8, strides=[1], device=cpu) = onnx::Constant[value= 0  0  0  0  0  0  0  0 [ CPULongType{8} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/pooling.py:622:0\n  %onnx::AveragePool_872 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], device=cpu) = onnx::Pad[mode=\"constant\"](%input.245, %onnx::Pad_871) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/pooling.py:622:0\n  %input.352 : Float(*, *, *, *, strides=[3840, 4, 4, 1], requires_grad=1, device=cpu) = onnx::AveragePool[ceil_mode=0, kernel_shape=[49, 49], pads=[0, 0, 0, 0], strides=[16, 20]](%onnx::AveragePool_872) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/pooling.py:622:0\n  %onnx::Sigmoid_874 : Float(*, *, *, *, strides=[512, 4, 4, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.352, %aspp_conv2.1.weight) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Shape_875 : Float(*, *, *, *, strides=[512, 4, 4, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_874) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py:293:0\n  %onnx::Unsqueeze_876 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:89:0\n  %onnx::Unsqueeze_877 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={128}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:89:0\n  %onnx::Concat_878 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_876)\n  %onnx::Concat_879 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_877)\n  %onnx::Cast_880 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_878, %onnx::Concat_879) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_881 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_875) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_882 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_883 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_884 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_885 : Long(2, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_881, %onnx::Slice_883, %onnx::Slice_884, %onnx::Slice_882) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_886 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_880) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_887 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_885, %onnx::Concat_886) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_888 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_889 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Mul_890 : Float(*, *, *, *, strides=[1048576, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"align_corners\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\"](%onnx::Shape_875, %onnx::Resize_888, %onnx::Resize_889, %onnx::Resize_887) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %input.356 : Float(*, *, *, *, strides=[1048576, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_870, %onnx::Mul_890) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:87:0\n  %y : Float(*, *, *, *, strides=[1048576, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.356, %conv_up1.weight, %conv_up1.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Gather_893 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Conv_481) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Gather_894 : Long(device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Unsqueeze_895 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_893, %onnx::Gather_894) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Gather_896 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Conv_481) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Gather_897 : Long(device=cpu) = onnx::Constant[value={3}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Unsqueeze_898 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_896, %onnx::Gather_897) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Concat_899 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_895)\n  %onnx::Concat_900 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_898)\n  %onnx::Cast_901 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_899, %onnx::Concat_900) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_902 : Long(4, strides=[1], device=cpu) = onnx::Shape(%y) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_903 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_904 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_905 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_906 : Long(2, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_902, %onnx::Slice_904, %onnx::Slice_905, %onnx::Slice_903) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_907 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_901) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_908 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_906, %onnx::Concat_907) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_909 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_910 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_911 : Float(*, *, *, *, strides=[4194304, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"pytorch_half_pixel\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\"](%y, %onnx::Resize_909, %onnx::Resize_910, %onnx::Resize_908) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_912 : Float(*, *, *, *, strides=[2097152, 32768, 256, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_481, %convs4.weight) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.360 : Float(*, *, *, *, strides=[6291456, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%onnx::Concat_911, %onnx::Concat_912) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:96:0\n  %input.368 : Float(*, *, *, *, strides=[4194304, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.360, %onnx::Conv_1099, %onnx::Conv_1100) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Shape_916 : Float(*, *, *, *, strides=[4194304, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.368) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Gather_917 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Conv_379) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Gather_918 : Long(device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Unsqueeze_919 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_917, %onnx::Gather_918) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Gather_920 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Conv_379) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Gather_921 : Long(device=cpu) = onnx::Constant[value={3}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Unsqueeze_922 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_920, %onnx::Gather_921) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Concat_923 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_919)\n  %onnx::Concat_924 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_922)\n  %onnx::Cast_925 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_923, %onnx::Concat_924) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_926 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_916) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_927 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_928 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_929 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_930 : Long(2, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_926, %onnx::Slice_928, %onnx::Slice_929, %onnx::Slice_927) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_931 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_925) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_932 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_930, %onnx::Concat_931) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_933 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_934 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_935 : Float(*, *, *, *, strides=[16777216, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"pytorch_half_pixel\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\"](%onnx::Shape_916, %onnx::Resize_933, %onnx::Resize_934, %onnx::Resize_932) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_936 : Float(*, *, *, *, strides=[4194304, 131072, 512, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_379, %convs2.weight) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.372 : Float(*, *, *, *, strides=[20971520, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%onnx::Concat_935, %onnx::Concat_936) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:100:0\n  %input.380 : Float(*, *, *, *, strides=[16777216, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.372, %onnx::Conv_1102, %onnx::Conv_1103) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_940 : Float(*, *, *, *, strides=[16777216, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.380) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %y.3 : Float(*, *, *, *, strides=[2490368, 131072, 512, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_940, %last.weight, %last.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Unsqueeze_942 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={512}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:103:0\n  %onnx::Unsqueeze_943 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1024}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:103:0\n  %onnx::Concat_944 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_942)\n  %onnx::Concat_945 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_943)\n  %onnx::Cast_946 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_944, %onnx::Concat_945) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_947 : Long(4, strides=[1], device=cpu) = onnx::Shape(%y.3) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_948 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_949 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_950 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_951 : Long(2, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_947, %onnx::Slice_949, %onnx::Slice_950, %onnx::Slice_948) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_952 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_946) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_953 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_951, %onnx::Concat_952) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_954 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_955 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %956 : Float(*, *, *, *, strides=[9961472, 524288, 1024, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"pytorch_half_pixel\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\"](%y.3, %onnx::Resize_954, %onnx::Resize_955, %onnx::Resize_953) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  return (%956)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, IMAGE_HEIGHT, IMAGE_WIDTH)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# For the Fastseg model, setting do_constant_folding to False is required\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# for PyTorch>1.5.1\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnx_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNX model exported to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/onnx/__init__.py:305\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03mExports a model into ONNX format. If ``model`` is not a\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m:class:`torch.jit.ScriptModule` nor a :class:`torch.jit.ScriptFunction`, this runs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m    model to the file ``f`` even if this is raised.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/onnx/utils.py:118\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         operator_export_type \u001b[38;5;241m=\u001b[39m OperatorExportTypes\u001b[38;5;241m.\u001b[39mONNX\n\u001b[0;32m--> 118\u001b[0m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/onnx/utils.py:738\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    735\u001b[0m     node_attr_to_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_function_extraction(\n\u001b[1;32m    736\u001b[0m         graph, export_modules_as_functions, \u001b[38;5;28mlist\u001b[39m(params_dict\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m export_params:\n\u001b[0;32m--> 738\u001b[0m     proto, export_map, val_use_external_data_format \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export_onnx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefer_weight_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_keep_init_as_ip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_add_node_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_attr_to_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m     proto, export_map, val_use_external_data_format \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39m_export_onnx(\n\u001b[1;32m    744\u001b[0m         {}, opset_version, dynamic_axes, \u001b[38;5;28;01mFalse\u001b[39;00m, operator_export_type,\n\u001b[1;32m    745\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m verbose, val_keep_init_as_ip, custom_opsets, val_add_node_names,\n\u001b[1;32m    746\u001b[0m         model_file_location, node_attr_to_name)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ONNX export failed: Couldn't export Python operator HardSwishJitAutoFn\n\nDefined at:\n/home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py(174): forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/container.py(141): forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/intel/.local/lib/python3.8/site-packages/fastseg/model/mobilenetv3.py(48): forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py(78): forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/intel/.local/lib/python3.8/site-packages/torch/jit/_trace.py(118): wrapper\n/home/intel/.local/lib/python3.8/site-packages/torch/jit/_trace.py(127): forward\n/home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/home/intel/.local/lib/python3.8/site-packages/torch/jit/_trace.py(1166): _get_trace_graph\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py(391): _trace_and_get_graph_from_model\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py(440): _create_jit_graph\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py(499): _model_to_graph\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py(719): _export\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py(118): export\n/home/intel/.local/lib/python3.8/site-packages/torch/onnx/__init__.py(305): export\n/tmp/ipykernel_4200/40378742.py(6): <cell line: 1>\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3398): run_code\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3338): run_ast_nodes\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3135): run_cell_async\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2936): _run_cell\n/home/intel/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2881): run_cell\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py(528): run_cell\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py(383): do_execute\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(728): execute_request\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(404): dispatch_shell\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(497): process_one\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(508): dispatch_queue\n/usr/lib/python3.8/asyncio/events.py(81): _run\n/usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n/usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n/home/intel/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py(199): start\n/home/intel/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py(712): start\n/home/intel/.local/lib/python3.8/site-packages/traitlets/config/application.py(976): launch_instance\n/home/intel/.local/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n/usr/lib/python3.8/runpy.py(87): _run_code\n/usr/lib/python3.8/runpy.py(194): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%x.1 : Float(1, 3, 512, 1024, strides=[1572864, 524288, 1024, 1], requires_grad=0, device=cpu),\n      %trunk.block2.0.se.conv_reduce.weight : Float(24, 72, 1, 1, strides=[72, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.0.se.conv_reduce.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block2.0.se.conv_expand.weight : Float(72, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.0.se.conv_expand.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block2.1.se.conv_reduce.weight : Float(32, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.1.se.conv_reduce.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block2.1.se.conv_expand.weight : Float(120, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.1.se.conv_expand.bias : Float(120, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block2.2.se.conv_reduce.weight : Float(32, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.2.se.conv_reduce.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block2.2.se.conv_expand.weight : Float(120, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block2.2.se.conv_expand.bias : Float(120, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block4.0.se.conv_reduce.weight : Float(120, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block4.0.se.conv_reduce.bias : Float(120, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block4.0.se.conv_expand.weight : Float(480, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block4.0.se.conv_expand.bias : Float(480, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block4.1.se.conv_reduce.weight : Float(168, 672, 1, 1, strides=[672, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block4.1.se.conv_reduce.bias : Float(168, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block4.1.se.conv_expand.weight : Float(672, 168, 1, 1, strides=[168, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block4.1.se.conv_expand.bias : Float(672, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.0.se.conv_reduce.weight : Float(168, 672, 1, 1, strides=[672, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.0.se.conv_reduce.bias : Float(168, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.0.se.conv_expand.weight : Float(672, 168, 1, 1, strides=[168, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.0.se.conv_expand.bias : Float(672, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.1.se.conv_reduce.weight : Float(240, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.1.se.conv_reduce.bias : Float(240, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.1.se.conv_expand.weight : Float(960, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.1.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.2.se.conv_reduce.weight : Float(240, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.2.se.conv_reduce.bias : Float(240, strides=[1], requires_grad=1, device=cpu),\n      %trunk.block5.2.se.conv_expand.weight : Float(960, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),\n      %trunk.block5.2.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cpu),\n      %aspp_conv2.1.weight : Float(128, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cpu),\n      %convs2.weight : Float(32, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cpu),\n      %convs4.weight : Float(64, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=1, device=cpu),\n      %conv_up1.weight : Float(128, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=1, device=cpu),\n      %conv_up1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n      %last.weight : Float(19, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=1, device=cpu),\n      %last.bias : Float(19, strides=[1], requires_grad=1, device=cpu),\n      %onnx::Conv_958 : Float(16, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_959 : Float(16, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_961 : Float(16, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_962 : Float(16, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_964 : Float(16, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_965 : Float(16, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_967 : Float(64, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_968 : Float(64, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_970 : Float(64, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_971 : Float(64, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_973 : Float(24, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_974 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_976 : Float(72, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_977 : Float(72, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_979 : Float(72, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_980 : Float(72, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_982 : Float(24, 72, 1, 1, strides=[72, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_983 : Float(24, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_985 : Float(72, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_986 : Float(72, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_988 : Float(72, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_989 : Float(72, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_991 : Float(40, 72, 1, 1, strides=[72, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_992 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_994 : Float(120, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_995 : Float(120, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_997 : Float(120, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_998 : Float(120, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1000 : Float(40, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1001 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1003 : Float(120, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1004 : Float(120, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1006 : Float(120, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1007 : Float(120, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1009 : Float(40, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1010 : Float(40, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1012 : Float(240, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1013 : Float(240, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1015 : Float(240, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1016 : Float(240, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1018 : Float(80, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1019 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1021 : Float(200, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1022 : Float(200, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1024 : Float(200, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1025 : Float(200, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1027 : Float(80, 200, 1, 1, strides=[200, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1028 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1030 : Float(184, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1031 : Float(184, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1033 : Float(184, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1034 : Float(184, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1036 : Float(80, 184, 1, 1, strides=[184, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1037 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1039 : Float(184, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1040 : Float(184, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1042 : Float(184, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1043 : Float(184, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1045 : Float(80, 184, 1, 1, strides=[184, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1046 : Float(80, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1048 : Float(480, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1049 : Float(480, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1051 : Float(480, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1052 : Float(480, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1054 : Float(112, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1055 : Float(112, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1057 : Float(672, 112, 1, 1, strides=[112, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1058 : Float(672, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1060 : Float(672, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1061 : Float(672, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1063 : Float(112, 672, 1, 1, strides=[672, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1064 : Float(112, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1066 : Float(672, 112, 1, 1, strides=[112, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1067 : Float(672, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1069 : Float(672, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1070 : Float(672, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1072 : Float(160, 672, 1, 1, strides=[672, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1073 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1075 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1076 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1078 : Float(960, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1079 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1081 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1082 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1084 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1085 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1087 : Float(960, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1088 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1090 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1091 : Float(160, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1093 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1094 : Float(960, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1096 : Float(128, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1097 : Float(128, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1099 : Float(128, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1100 : Float(128, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Conv_1102 : Float(128, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Conv_1103 : Float(128, strides=[1], requires_grad=0, device=cpu)):\n  %onnx::Unsqueeze_334 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_335 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Unsqueeze_336 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_337 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Concat_338 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_334)\n  %onnx::Concat_339 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_335)\n  %onnx::Concat_340 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_336)\n  %onnx::Concat_341 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_337)\n  %onnx::Shape_342 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_338, %onnx::Concat_339, %onnx::Concat_340, %onnx::Concat_341) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_343 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_334)\n  %onnx::Concat_344 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_335)\n  %onnx::Concat_345 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_336)\n  %onnx::Concat_346 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_337)\n  %onnx::Cast_347 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_343, %onnx::Concat_344, %onnx::Concat_345, %onnx::Concat_346) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_348 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_349 : Long(1, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_342) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_350 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%onnx::Gather_349, %onnx::Gather_348) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_351 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_352 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_353 : Long(device=cpu) = onnx::Mul(%onnx::Mul_351, %onnx::Mul_352) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::ConstantOfShape_354 : Long(1, strides=[1], device=cpu) = onnx::Sub(%onnx::Sub_353, %onnx::Sub_350) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_355 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_347) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_356 : Long(4, device=cpu) = onnx::ConstantOfShape[value={0}](%onnx::ConstantOfShape_354) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_357 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_355, %onnx::Concat_356) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_358 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_359 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape(%onnx::Reshape_357, %onnx::Reshape_358) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_360 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_361 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_362 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_363 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Transpose_364 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice(%onnx::Slice_359, %onnx::Slice_361, %onnx::Slice_362, %onnx::Slice_360, %onnx::Slice_363) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_365 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%onnx::Transpose_364) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_366 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Cast_367 : Long(8, strides=[1], device=cpu) = onnx::Reshape(%onnx::Reshape_365, %onnx::Reshape_366) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_368 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_367) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_369 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Conv_370 : Float(*, *, *, *, strides=[1577475, 525825, 1025, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\"](%x.1, %onnx::Pad_368, %onnx::Pad_369) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %x : Float(*, 16, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%onnx::Conv_370, %onnx::Conv_958, %onnx::Conv_959) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:72:0\n  %input.3 : Float(*, *, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.8 : Float(*, *, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=16, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input.3, %onnx::Conv_961, %onnx::Conv_962) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_376 : Float(*, *, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.8) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Add_963 : Float(*, *, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_376, %onnx::Conv_964, %onnx::Conv_965) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_379 : Float(*, *, *, *, strides=[2097152, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_963, %input.3) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:186:0\n  %input.20 : Float(*, *, *, *, strides=[8388608, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_379, %onnx::Conv_967, %onnx::Conv_968) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Shape_382 : Float(*, *, *, *, strides=[8388608, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.20) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Gather_383 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_382) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_384 : Long(device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_385 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_383, %onnx::Gather_384) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_386 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_382) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_387 : Long(device=cpu) = onnx::Constant[value={3}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_388 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_386, %onnx::Gather_387) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_389 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_390 : Long(device=cpu) = onnx::Div(%onnx::Div_385, %onnx::Div_389) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_391 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_390) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Neg_392 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_391) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_393 : Long(requires_grad=0, device=cpu) = onnx::Neg(%onnx::Neg_392) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Sub_394 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Mul_395 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_393, %onnx::Sub_394) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Mul_396 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %onnx::Add_397 : Long(requires_grad=0, device=cpu) = onnx::Mul(%onnx::Mul_395, %onnx::Mul_396) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_398 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_399 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_397, %onnx::Add_398) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_400 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Sub_401 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_399, %onnx::Add_400) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_402 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_401, %onnx::Div_385) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_403 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_404 : Long(device=cpu) = onnx::Div(%onnx::Div_388, %onnx::Div_403) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_405 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_404) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Neg_406 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_405) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_407 : Long(requires_grad=0, device=cpu) = onnx::Neg(%onnx::Neg_406) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Sub_408 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Mul_409 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_407, %onnx::Sub_408) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Mul_410 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %onnx::Add_411 : Long(requires_grad=0, device=cpu) = onnx::Mul(%onnx::Mul_409, %onnx::Mul_410) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_412 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_413 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_411, %onnx::Add_412) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_414 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Sub_415 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_413, %onnx::Add_414) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_416 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_415, %onnx::Div_388) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_417 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_418 : Long(device=cpu) = onnx::Div(%onnx::Div_416, %onnx::Div_417) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_419 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_418) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_420 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_419) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Div_421 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_422 : Long(device=cpu) = onnx::Div(%onnx::Div_416, %onnx::Div_421) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_423 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_422) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_424 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_423) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_425 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Div_416, %onnx::Sub_424) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Div_426 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_427 : Long(device=cpu) = onnx::Div(%onnx::Div_402, %onnx::Div_426) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_428 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_427) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_429 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_428) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Div_430 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_431 : Long(device=cpu) = onnx::Div(%onnx::Div_402, %onnx::Div_430) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_432 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_431) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_433 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_432) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_434 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Div_402, %onnx::Sub_433) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Concat_435 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_420)\n  %onnx::Concat_436 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_425)\n  %onnx::Concat_437 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_429)\n  %onnx::Concat_438 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_434)\n  %onnx::Shape_439 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_435, %onnx::Concat_436, %onnx::Concat_437, %onnx::Concat_438) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_440 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_420)\n  %onnx::Concat_441 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_425)\n  %onnx::Concat_442 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_429)\n  %onnx::Concat_443 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_434)\n  %onnx::Cast_444 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_440, %onnx::Concat_441, %onnx::Concat_442, %onnx::Concat_443) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_445 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_446 : Long(1, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_439) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_447 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%onnx::Gather_446, %onnx::Gather_445) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_448 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_449 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_450 : Long(device=cpu) = onnx::Mul(%onnx::Mul_448, %onnx::Mul_449) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::ConstantOfShape_451 : Long(1, strides=[1], device=cpu) = onnx::Sub(%onnx::Sub_450, %onnx::Sub_447) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_452 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_444) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_453 : Long(4, device=cpu) = onnx::ConstantOfShape[value={0}](%onnx::ConstantOfShape_451) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_454 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_452, %onnx::Concat_453) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_455 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_456 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape(%onnx::Reshape_454, %onnx::Reshape_455) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_457 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_458 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_459 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_460 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Transpose_461 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice(%onnx::Slice_456, %onnx::Slice_458, %onnx::Slice_459, %onnx::Slice_457, %onnx::Slice_460) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_462 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%onnx::Transpose_461) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Cast_464 : Long(8, strides=[1], device=cpu) = onnx::Reshape(%onnx::Reshape_462, %onnx::Reshape_463) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_465 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_464) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_466 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Conv_467 : Float(*, *, *, *, strides=[8437824, 131841, 513, 1], requires_grad=1, device=cpu) = onnx::Pad[mode=\"constant\"](%onnx::Shape_382, %onnx::Pad_465, %onnx::Pad_466) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %input.28 : Float(*, *, *, *, strides=[2097152, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=64, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%onnx::Conv_467, %onnx::Conv_970, %onnx::Conv_971) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:72:0\n  %onnx::Conv_470 : Float(*, *, *, *, strides=[2097152, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.28) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.36 : Float(*, *, *, *, strides=[786432, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_470, %onnx::Conv_973, %onnx::Conv_974) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.44 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.36, %onnx::Conv_976, %onnx::Conv_977) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_475 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.44) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.52 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=72, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%onnx::Conv_475, %onnx::Conv_979, %onnx::Conv_980) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_478 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.52) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Add_981 : Float(*, *, *, *, strides=[786432, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_478, %onnx::Conv_982, %onnx::Conv_983) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_481 : Float(*, *, *, *, strides=[786432, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_981, %input.36) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %input.64 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_481, %onnx::Conv_985, %onnx::Conv_986) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Shape_484 : Float(*, *, *, *, strides=[2359296, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.64) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Gather_485 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_484) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_486 : Long(device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_487 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_485, %onnx::Gather_486) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_488 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_484) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Gather_489 : Long(device=cpu) = onnx::Constant[value={3}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_490 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_488, %onnx::Gather_489) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:67:0\n  %onnx::Div_491 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_492 : Long(device=cpu) = onnx::Div(%onnx::Div_487, %onnx::Div_491) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_493 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_492) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Neg_494 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_493) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_495 : Long(requires_grad=0, device=cpu) = onnx::Neg(%onnx::Neg_494) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Sub_496 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Mul_497 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_495, %onnx::Sub_496) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Mul_498 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %onnx::Add_499 : Long(requires_grad=0, device=cpu) = onnx::Mul(%onnx::Mul_497, %onnx::Mul_498) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_500 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_501 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_499, %onnx::Add_500) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_502 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Sub_503 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_501, %onnx::Add_502) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_504 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_503, %onnx::Div_487) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_505 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_506 : Long(device=cpu) = onnx::Div(%onnx::Div_490, %onnx::Div_505) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_507 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_506) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Neg_508 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_507) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_509 : Long(requires_grad=0, device=cpu) = onnx::Neg(%onnx::Neg_508) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Sub_510 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Mul_511 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_509, %onnx::Sub_510) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Mul_512 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %onnx::Add_513 : Long(requires_grad=0, device=cpu) = onnx::Mul(%onnx::Mul_511, %onnx::Mul_512) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_514 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_515 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_513, %onnx::Add_514) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Add_516 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Sub_517 : Long(requires_grad=0, device=cpu) = onnx::Add(%onnx::Add_515, %onnx::Add_516) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_518 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Sub_517, %onnx::Div_490) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:47:0\n  %onnx::Div_519 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_520 : Long(device=cpu) = onnx::Div(%onnx::Div_518, %onnx::Div_519) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_521 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_520) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_522 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_521) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Div_523 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_524 : Long(device=cpu) = onnx::Div(%onnx::Div_518, %onnx::Div_523) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_525 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_524) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_526 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_525) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_527 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Div_518, %onnx::Sub_526) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Div_528 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_529 : Long(device=cpu) = onnx::Div(%onnx::Div_504, %onnx::Div_528) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_530 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_529) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_531 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_530) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Div_532 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_533 : Long(device=cpu) = onnx::Div(%onnx::Div_504, %onnx::Div_532) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Cast_534 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_533) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Sub_535 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7](%onnx::Cast_534) # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_536 : Long(requires_grad=0, device=cpu) = onnx::Sub(%onnx::Div_504, %onnx::Sub_535) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Concat_537 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_522)\n  %onnx::Concat_538 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_527)\n  %onnx::Concat_539 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_531)\n  %onnx::Concat_540 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_536)\n  %onnx::Shape_541 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_537, %onnx::Concat_538, %onnx::Concat_539, %onnx::Concat_540) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_542 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_522)\n  %onnx::Concat_543 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_527)\n  %onnx::Concat_544 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_531)\n  %onnx::Concat_545 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_536)\n  %onnx::Cast_546 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_542, %onnx::Concat_543, %onnx::Concat_544, %onnx::Concat_545) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_547 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_548 : Long(1, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_541) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_549 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%onnx::Gather_548, %onnx::Gather_547) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_550 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_551 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_552 : Long(device=cpu) = onnx::Mul(%onnx::Mul_550, %onnx::Mul_551) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::ConstantOfShape_553 : Long(1, strides=[1], device=cpu) = onnx::Sub(%onnx::Sub_552, %onnx::Sub_549) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_554 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_546) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_555 : Long(4, device=cpu) = onnx::ConstantOfShape[value={0}](%onnx::ConstantOfShape_553) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_556 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_554, %onnx::Concat_555) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_557 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_558 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape(%onnx::Reshape_556, %onnx::Reshape_557) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_559 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_560 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_561 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_562 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Transpose_563 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice(%onnx::Slice_558, %onnx::Slice_560, %onnx::Slice_561, %onnx::Slice_559, %onnx::Slice_562) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_564 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%onnx::Transpose_563) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_565 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Cast_566 : Long(8, strides=[1], device=cpu) = onnx::Reshape(%onnx::Reshape_564, %onnx::Reshape_565) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_567 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_566) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_568 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Conv_569 : Float(*, *, *, *, strides=[2442888, 33929, 259, 1], requires_grad=1, device=cpu) = onnx::Pad[mode=\"constant\"](%onnx::Shape_484, %onnx::Pad_567, %onnx::Pad_568) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %input.72 : Float(*, *, *, *, strides=[589824, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=72, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[2, 2]](%onnx::Conv_569, %onnx::Conv_988, %onnx::Conv_989) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:72:0\n  %onnx::ReduceMean_572 : Float(*, *, *, *, strides=[589824, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.72) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.76 : Float(*, *, *, *, strides=[72, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_572) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.80 : Float(*, *, *, *, strides=[24, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.76, %trunk.block2.0.se.conv_reduce.weight, %trunk.block2.0.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_575 : Float(*, *, *, *, strides=[24, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.80) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se : Float(*, *, *, *, strides=[72, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_575, %trunk.block2.0.se.conv_expand.weight, %trunk.block2.0.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_577 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_578 : Float(*, *, *, *, strides=[72, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se, %onnx::Add_577) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_579 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_578) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_580 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_581 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_582 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_580) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_583 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_581) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_584 : Float(*, *, *, *, strides=[72, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_579, %onnx::Clip_582, %onnx::Clip_583) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_585 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_586 : Float(*, *, *, *, strides=[72, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_584, %onnx::Div_585) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.84 : Float(*, *, *, *, strides=[589824, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_572, %onnx::Mul_586) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %input.92 : Float(*, *, *, *, strides=[327680, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.84, %onnx::Conv_991, %onnx::Conv_992) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.100 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.92, %onnx::Conv_994, %onnx::Conv_995) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_592 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.100) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.108 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=120, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%onnx::Conv_592, %onnx::Conv_997, %onnx::Conv_998) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_595 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.108) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.112 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_595) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.116 : Float(*, *, *, *, strides=[32, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.112, %trunk.block2.1.se.conv_reduce.weight, %trunk.block2.1.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_598 : Float(*, *, *, *, strides=[32, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.116) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.3 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_598, %trunk.block2.1.se.conv_expand.weight, %trunk.block2.1.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_600 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_601 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.3, %onnx::Add_600) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_602 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_601) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_603 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_604 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_605 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_603) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_606 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_604) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_607 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_602, %onnx::Clip_605, %onnx::Clip_606) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_608 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_609 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_607, %onnx::Div_608) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.120 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_595, %onnx::Mul_609) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %onnx::Add_999 : Float(*, *, *, *, strides=[327680, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.120, %onnx::Conv_1000, %onnx::Conv_1001) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_613 : Float(*, *, *, *, strides=[327680, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_999, %input.92) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %input.132 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_613, %onnx::Conv_1003, %onnx::Conv_1004) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_616 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.132) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.140 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=120, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%onnx::Conv_616, %onnx::Conv_1006, %onnx::Conv_1007) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_619 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.140) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %input.144 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_619) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.148 : Float(*, *, *, *, strides=[32, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.144, %trunk.block2.2.se.conv_reduce.weight, %trunk.block2.2.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_622 : Float(*, *, *, *, strides=[32, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.148) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.7 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_622, %trunk.block2.2.se.conv_expand.weight, %trunk.block2.2.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_624 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_625 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.7, %onnx::Add_624) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_626 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_625) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_627 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_628 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_629 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_627) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_630 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_628) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_631 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_626, %onnx::Clip_629, %onnx::Clip_630) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_632 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_633 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_631, %onnx::Div_632) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.152 : Float(*, *, *, *, strides=[983040, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_619, %onnx::Mul_633) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %onnx::Add_1008 : Float(*, *, *, *, strides=[327680, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.152, %onnx::Conv_1009, %onnx::Conv_1010) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_637 : Float(*, *, *, *, strides=[327680, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1008, %onnx::Conv_613) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.4 : Float(*, *, *, *, strides=[1966080, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_637, %onnx::Conv_1012, %onnx::Conv_1013) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %x.11 : Float(*, *, *, *, strides=[1966080, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.4) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %onnx::Unsqueeze_641 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_642 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Unsqueeze_643 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_644 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Concat_645 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_641)\n  %onnx::Concat_646 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_642)\n  %onnx::Concat_647 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_643)\n  %onnx::Concat_648 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_644)\n  %onnx::Shape_649 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_645, %onnx::Concat_646, %onnx::Concat_647, %onnx::Concat_648) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_650 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_641)\n  %onnx::Concat_651 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_642)\n  %onnx::Concat_652 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_643)\n  %onnx::Concat_653 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_644)\n  %onnx::Cast_654 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_650, %onnx::Concat_651, %onnx::Concat_652, %onnx::Concat_653) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_655 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_656 : Long(1, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_649) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_657 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%onnx::Gather_656, %onnx::Gather_655) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_658 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_659 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_660 : Long(device=cpu) = onnx::Mul(%onnx::Mul_658, %onnx::Mul_659) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::ConstantOfShape_661 : Long(1, strides=[1], device=cpu) = onnx::Sub(%onnx::Sub_660, %onnx::Sub_657) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_662 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_654) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_663 : Long(4, device=cpu) = onnx::ConstantOfShape[value={0}](%onnx::ConstantOfShape_661) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_664 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_662, %onnx::Concat_663) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_665 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_666 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape(%onnx::Reshape_664, %onnx::Reshape_665) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_667 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_668 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_669 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_670 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Transpose_671 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice(%onnx::Slice_666, %onnx::Slice_668, %onnx::Slice_669, %onnx::Slice_667, %onnx::Slice_670) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_672 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%onnx::Transpose_671) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_673 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Cast_674 : Long(8, strides=[1], device=cpu) = onnx::Reshape(%onnx::Reshape_672, %onnx::Reshape_673) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_675 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_674) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_676 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Conv_677 : Float(*, *, *, *, strides=[2154240, 8976, 132, 1], requires_grad=1, device=cpu) = onnx::Pad[mode=\"constant\"](%x.11, %onnx::Pad_675, %onnx::Pad_676) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %x.8 : Float(*, *, *, *, strides=[1966080, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=240, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_677, %onnx::Conv_1015, %onnx::Conv_1016) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:72:0\n  %input.113 : Float(*, *, *, *, strides=[1966080, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.8) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.172 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.113, %onnx::Conv_1018, %onnx::Conv_1019) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %x.12 : Float(*, *, *, *, strides=[1638400, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.172, %onnx::Conv_1021, %onnx::Conv_1022) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.121 : Float(*, *, *, *, strides=[1638400, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.12) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.16 : Float(*, *, *, *, strides=[1638400, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=200, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%input.121, %onnx::Conv_1024, %onnx::Conv_1025) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.125 : Float(*, *, *, *, strides=[1638400, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.16) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %onnx::Add_1026 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.125, %onnx::Conv_1027, %onnx::Conv_1028) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_691 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1026, %input.172) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.20 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_691, %onnx::Conv_1030, %onnx::Conv_1031) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.133 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.20) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.24 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=184, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%input.133, %onnx::Conv_1033, %onnx::Conv_1034) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.137 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.24) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %onnx::Add_1035 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.137, %onnx::Conv_1036, %onnx::Conv_1037) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_700 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1035, %onnx::Conv_691) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.28 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_700, %onnx::Conv_1039, %onnx::Conv_1040) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.145 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.28) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.32 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=184, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%input.145, %onnx::Conv_1042, %onnx::Conv_1043) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.149 : Float(*, *, *, *, strides=[1507328, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.32) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %onnx::Add_1044 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.149, %onnx::Conv_1045, %onnx::Conv_1046) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_709 : Float(*, *, *, *, strides=[655360, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1044, %onnx::Conv_700) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.36 : Float(*, *, *, *, strides=[3932160, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_709, %onnx::Conv_1048, %onnx::Conv_1049) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.157 : Float(*, *, *, *, strides=[3932160, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.36) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.40 : Float(*, *, *, *, strides=[3932160, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=480, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%input.157, %onnx::Conv_1051, %onnx::Conv_1052) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_715 : Float(*, *, *, *, strides=[3932160, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.40) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.220 : Float(*, *, *, *, strides=[480, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_715) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.224 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.220, %trunk.block4.0.se.conv_reduce.weight, %trunk.block4.0.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_718 : Float(*, *, *, *, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.224) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.11 : Float(*, *, *, *, strides=[480, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_718, %trunk.block4.0.se.conv_expand.weight, %trunk.block4.0.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_720 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_721 : Float(*, *, *, *, strides=[480, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.11, %onnx::Add_720) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_722 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_721) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_723 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_724 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_725 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_723) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_726 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_724) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_727 : Float(*, *, *, *, strides=[480, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_722, %onnx::Clip_725, %onnx::Clip_726) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_728 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_729 : Float(*, *, *, *, strides=[480, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_727, %onnx::Div_728) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.228 : Float(*, *, *, *, strides=[3932160, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_715, %onnx::Mul_729) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %input.236 : Float(*, *, *, *, strides=[917504, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.228, %onnx::Conv_1054, %onnx::Conv_1055) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %x.44 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.236, %onnx::Conv_1057, %onnx::Conv_1058) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.175 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.44) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.48 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[2, 2], group=672, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%input.175, %onnx::Conv_1060, %onnx::Conv_1061) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_738 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.48) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.248 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_738) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.252 : Float(*, *, *, *, strides=[168, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.248, %trunk.block4.1.se.conv_reduce.weight, %trunk.block4.1.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_741 : Float(*, *, *, *, strides=[168, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.252) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.15 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_741, %trunk.block4.1.se.conv_expand.weight, %trunk.block4.1.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_743 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_744 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.15, %onnx::Add_743) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_745 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_744) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_746 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_747 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_748 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_746) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_749 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_747) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_750 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_745, %onnx::Clip_748, %onnx::Clip_749) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_751 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_752 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_750, %onnx::Div_751) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.256 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_738, %onnx::Mul_752) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %onnx::Add_1062 : Float(*, *, *, *, strides=[917504, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.256, %onnx::Conv_1063, %onnx::Conv_1064) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_756 : Float(*, *, *, *, strides=[917504, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1062, %input.236) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.52 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_756, %onnx::Conv_1066, %onnx::Conv_1067) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %x.37 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.52) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %onnx::Unsqueeze_760 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_761 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Unsqueeze_762 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]() # /home/intel/.local/lib/python3.8/site-packages/torch/_tensor.py:647:0\n  %onnx::Unsqueeze_763 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]() # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:71:0\n  %onnx::Concat_764 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_760)\n  %onnx::Concat_765 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_761)\n  %onnx::Concat_766 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_762)\n  %onnx::Concat_767 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_763)\n  %onnx::Shape_768 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_764, %onnx::Concat_765, %onnx::Concat_766, %onnx::Concat_767) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_769 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_760)\n  %onnx::Concat_770 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_761)\n  %onnx::Concat_771 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_762)\n  %onnx::Concat_772 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_763)\n  %onnx::Cast_773 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_769, %onnx::Concat_770, %onnx::Concat_771, %onnx::Concat_772) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_774 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Gather_775 : Long(1, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_768) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_776 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%onnx::Gather_775, %onnx::Gather_774) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_777 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Mul_778 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Sub_779 : Long(device=cpu) = onnx::Mul(%onnx::Mul_777, %onnx::Mul_778) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::ConstantOfShape_780 : Long(1, strides=[1], device=cpu) = onnx::Sub(%onnx::Sub_779, %onnx::Sub_776) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_781 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_773) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Concat_782 : Long(4, device=cpu) = onnx::ConstantOfShape[value={0}](%onnx::ConstantOfShape_780) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_783 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_781, %onnx::Concat_782) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_784 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_785 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape(%onnx::Reshape_783, %onnx::Reshape_784) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_786 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_787 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_788 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Slice_789 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Transpose_790 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice(%onnx::Slice_785, %onnx::Slice_787, %onnx::Slice_788, %onnx::Slice_786, %onnx::Slice_789) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_791 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%onnx::Transpose_790) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Reshape_792 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Cast_793 : Long(8, strides=[1], device=cpu) = onnx::Reshape(%onnx::Reshape_791, %onnx::Reshape_792) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_794 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_793) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Pad_795 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %onnx::Conv_796 : Float(*, *, *, *, strides=[7741440, 11520, 144, 1], requires_grad=1, device=cpu) = onnx::Pad[mode=\"constant\"](%x.37, %onnx::Pad_794, %onnx::Pad_795) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:4364:0\n  %x.56 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[4, 4], group=672, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_796, %onnx::Conv_1069, %onnx::Conv_1070) # /home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:72:0\n  %onnx::ReduceMean_799 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.56) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.272 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_799) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.276 : Float(*, *, *, *, strides=[168, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.272, %trunk.block5.0.se.conv_reduce.weight, %trunk.block5.0.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_802 : Float(*, *, *, *, strides=[168, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.276) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.19 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_802, %trunk.block5.0.se.conv_expand.weight, %trunk.block5.0.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_804 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_805 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.19, %onnx::Add_804) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_806 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_805) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_807 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_808 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_809 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_807) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_810 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_808) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_811 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_806, %onnx::Clip_809, %onnx::Clip_810) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_812 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_813 : Float(*, *, *, *, strides=[672, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_811, %onnx::Div_812) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.280 : Float(*, *, *, *, strides=[5505024, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_799, %onnx::Mul_813) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %input.288 : Float(*, *, *, *, strides=[1310720, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.280, %onnx::Conv_1072, %onnx::Conv_1073) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %x.60 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.288, %onnx::Conv_1075, %onnx::Conv_1076) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.209 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.60) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.64 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[4, 4], group=960, kernel_shape=[5, 5], pads=[8, 8, 8, 8], strides=[1, 1]](%input.209, %onnx::Conv_1078, %onnx::Conv_1079) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_822 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.64) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.300 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_822) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.304 : Float(*, *, *, *, strides=[240, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.300, %trunk.block5.1.se.conv_reduce.weight, %trunk.block5.1.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_825 : Float(*, *, *, *, strides=[240, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.304) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.23 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_825, %trunk.block5.1.se.conv_expand.weight, %trunk.block5.1.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_827 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_828 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.23, %onnx::Add_827) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_829 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_828) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_830 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_831 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_832 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_830) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_833 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_831) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_834 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_829, %onnx::Clip_832, %onnx::Clip_833) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_835 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_836 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_834, %onnx::Div_835) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.308 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_822, %onnx::Mul_836) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %onnx::Add_1080 : Float(*, *, *, *, strides=[1310720, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.308, %onnx::Conv_1081, %onnx::Conv_1082) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_840 : Float(*, *, *, *, strides=[1310720, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1080, %input.288) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.68 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_840, %onnx::Conv_1084, %onnx::Conv_1085) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.227 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.68) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %x.72 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[4, 4], group=960, kernel_shape=[5, 5], pads=[8, 8, 8, 8], strides=[1, 1]](%input.227, %onnx::Conv_1087, %onnx::Conv_1088) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::ReduceMean_846 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.72) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.324 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%onnx::ReduceMean_846) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:114:0\n  %input.328 : Float(*, *, *, *, strides=[240, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.324, %trunk.block5.2.se.conv_reduce.weight, %trunk.block5.2.se.conv_reduce.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_849 : Float(*, *, *, *, strides=[240, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.328) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %x_se.27 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_849, %trunk.block5.2.se.conv_expand.weight, %trunk.block5.2.se.conv_expand.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Add_851 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Relu_852 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%x_se.27, %onnx::Add_851) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %onnx::Clip_853 : Float(*, *, *, *, device=cpu) = onnx::Relu(%onnx::Relu_852) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_854 : Float(device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Cast_855 : Float(device=cpu) = onnx::Constant[value={6}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_856 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_854) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Clip_857 : Float(device=cpu) = onnx::Cast[to=1](%onnx::Cast_855) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_858 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Clip(%onnx::Clip_853, %onnx::Clip_856, %onnx::Clip_857) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1519:0\n  %onnx::Div_859 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Mul_860 : Float(*, *, *, *, strides=[960, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Div(%onnx::Div_858, %onnx::Div_859) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations.py:91:0\n  %input.332 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::ReduceMean_846, %onnx::Mul_860) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:118:0\n  %onnx::Add_1089 : Float(*, *, *, *, strides=[1310720, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.332, %onnx::Conv_1090, %onnx::Conv_1091) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_864 : Float(*, *, *, *, strides=[1310720, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1089, %onnx::Conv_840) # /home/intel/.local/lib/python3.8/site-packages/geffnet/efficientnet_builder.py:250:0\n  %x.76 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[4, 4], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_864, %onnx::Conv_1093, %onnx::Conv_1094) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.245 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], requires_grad=1, device=cpu) = ^HardSwishJitAutoFn()(%x.76) # /home/intel/.local/lib/python3.8/site-packages/geffnet/activations/activations_me.py:174:0\n  %input.348 : Float(*, *, *, *, strides=[1048576, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.245, %onnx::Conv_1096, %onnx::Conv_1097) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Mul_870 : Float(*, *, *, *, strides=[1048576, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.348) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Pad_871 : Long(8, strides=[1], device=cpu) = onnx::Constant[value= 0  0  0  0  0  0  0  0 [ CPULongType{8} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/pooling.py:622:0\n  %onnx::AveragePool_872 : Float(*, *, *, *, strides=[7864320, 8192, 128, 1], device=cpu) = onnx::Pad[mode=\"constant\"](%input.245, %onnx::Pad_871) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/pooling.py:622:0\n  %input.352 : Float(*, *, *, *, strides=[3840, 4, 4, 1], requires_grad=1, device=cpu) = onnx::AveragePool[ceil_mode=0, kernel_shape=[49, 49], pads=[0, 0, 0, 0], strides=[16, 20]](%onnx::AveragePool_872) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/pooling.py:622:0\n  %onnx::Sigmoid_874 : Float(*, *, *, *, strides=[512, 4, 4, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.352, %aspp_conv2.1.weight) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Shape_875 : Float(*, *, *, *, strides=[512, 4, 4, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_874) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py:293:0\n  %onnx::Unsqueeze_876 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:89:0\n  %onnx::Unsqueeze_877 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={128}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:89:0\n  %onnx::Concat_878 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_876)\n  %onnx::Concat_879 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_877)\n  %onnx::Cast_880 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_878, %onnx::Concat_879) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_881 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_875) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_882 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_883 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_884 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_885 : Long(2, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_881, %onnx::Slice_883, %onnx::Slice_884, %onnx::Slice_882) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_886 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_880) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_887 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_885, %onnx::Concat_886) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_888 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_889 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Mul_890 : Float(*, *, *, *, strides=[1048576, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"align_corners\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\"](%onnx::Shape_875, %onnx::Resize_888, %onnx::Resize_889, %onnx::Resize_887) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %input.356 : Float(*, *, *, *, strides=[1048576, 8192, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_870, %onnx::Mul_890) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:87:0\n  %y : Float(*, *, *, *, strides=[1048576, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.356, %conv_up1.weight, %conv_up1.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Gather_893 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Conv_481) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Gather_894 : Long(device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Unsqueeze_895 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_893, %onnx::Gather_894) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Gather_896 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Conv_481) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Gather_897 : Long(device=cpu) = onnx::Constant[value={3}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Unsqueeze_898 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_896, %onnx::Gather_897) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:94:0\n  %onnx::Concat_899 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_895)\n  %onnx::Concat_900 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_898)\n  %onnx::Cast_901 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_899, %onnx::Concat_900) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_902 : Long(4, strides=[1], device=cpu) = onnx::Shape(%y) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_903 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_904 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_905 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_906 : Long(2, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_902, %onnx::Slice_904, %onnx::Slice_905, %onnx::Slice_903) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_907 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_901) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_908 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_906, %onnx::Concat_907) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_909 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_910 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_911 : Float(*, *, *, *, strides=[4194304, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"pytorch_half_pixel\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\"](%y, %onnx::Resize_909, %onnx::Resize_910, %onnx::Resize_908) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_912 : Float(*, *, *, *, strides=[2097152, 32768, 256, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_481, %convs4.weight) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.360 : Float(*, *, *, *, strides=[6291456, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%onnx::Concat_911, %onnx::Concat_912) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:96:0\n  %input.368 : Float(*, *, *, *, strides=[4194304, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.360, %onnx::Conv_1099, %onnx::Conv_1100) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Shape_916 : Float(*, *, *, *, strides=[4194304, 32768, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.368) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %onnx::Gather_917 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Conv_379) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Gather_918 : Long(device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Unsqueeze_919 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_917, %onnx::Gather_918) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Gather_920 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Conv_379) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Gather_921 : Long(device=cpu) = onnx::Constant[value={3}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Unsqueeze_922 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_920, %onnx::Gather_921) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:98:0\n  %onnx::Concat_923 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_919)\n  %onnx::Concat_924 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_922)\n  %onnx::Cast_925 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_923, %onnx::Concat_924) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_926 : Long(4, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_916) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_927 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_928 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_929 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_930 : Long(2, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_926, %onnx::Slice_928, %onnx::Slice_929, %onnx::Slice_927) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_931 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_925) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_932 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_930, %onnx::Concat_931) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_933 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_934 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_935 : Float(*, *, *, *, strides=[16777216, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"pytorch_half_pixel\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\"](%onnx::Shape_916, %onnx::Resize_933, %onnx::Resize_934, %onnx::Resize_932) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_936 : Float(*, *, *, *, strides=[4194304, 131072, 512, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_379, %convs2.weight) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %input.372 : Float(*, *, *, *, strides=[20971520, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%onnx::Concat_935, %onnx::Concat_936) # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:100:0\n  %input.380 : Float(*, *, *, *, strides=[16777216, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.372, %onnx::Conv_1102, %onnx::Conv_1103) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Conv_940 : Float(*, *, *, *, strides=[16777216, 131072, 512, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.380) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n  %y.3 : Float(*, *, *, *, strides=[2490368, 131072, 512, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%onnx::Conv_940, %last.weight, %last.bias) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n  %onnx::Unsqueeze_942 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={512}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:103:0\n  %onnx::Unsqueeze_943 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1024}]() # /home/intel/.local/lib/python3.8/site-packages/fastseg/model/lraspp.py:103:0\n  %onnx::Concat_944 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_942)\n  %onnx::Concat_945 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%onnx::Unsqueeze_943)\n  %onnx::Cast_946 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_944, %onnx::Concat_945) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_947 : Long(4, strides=[1], device=cpu) = onnx::Shape(%y.3) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_948 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_949 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Slice_950 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_951 : Long(2, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_947, %onnx::Slice_949, %onnx::Slice_950, %onnx::Slice_948) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Concat_952 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7](%onnx::Cast_946) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_953 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Concat_951, %onnx::Concat_952) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_954 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %onnx::Resize_955 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]() # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  %956 : Float(*, *, *, *, strides=[9961472, 524288, 1024, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"pytorch_half_pixel\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\"](%y.3, %onnx::Resize_954, %onnx::Resize_955, %onnx::Resize_953) # /home/intel/.local/lib/python3.8/site-packages/torch/nn/functional.py:3919:0\n  return (%956)\n"
     ]
    }
   ],
   "source": [
    "if not onnx_path.exists():\n",
    "    dummy_input = torch.randn(1, 3, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "\n",
    "    # For the Fastseg model, setting do_constant_folding to False is required\n",
    "    # for PyTorch>1.5.1\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=False,\n",
    "    )\n",
    "    print(f\"ONNX model exported to {onnx_path}.\")\n",
    "else:\n",
    "    print(f\"ONNX model {onnx_path} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490241b",
   "metadata": {
    "id": "6JSoEIk60uxV"
   },
   "source": [
    "### Convert ONNX Model to OpenVINO IR Format\n",
    "\n",
    "Call the OpenVINO Model Optimizer tool to convert the ONNX model to OpenVINO IR with FP16 precision. The models are saved to the current directory. We add the mean values to the model and scale the output with the standard deviation with `--scale_values`. With these options, it is not necessary to normalize input data before propagating it through the network.\n",
    "\n",
    "See the [Model Optimizer Developer Guide](https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html) for more information about Model Optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99ea10",
   "metadata": {},
   "source": [
    "Executing this command may take a while. There may be some errors or warnings in the output. Model Optimization was successful if the last lines of the output include `[ SUCCESS ] Generated IR version 11 model.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e8029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the command for Model Optimizer\n",
    "mo_command = f\"\"\"mo\n",
    "                 --input_model \"{onnx_path}\"\n",
    "                 --input_shape \"[1,3, {IMAGE_HEIGHT}, {IMAGE_WIDTH}]\"\n",
    "                 --mean_values=\"[123.675, 116.28 , 103.53]\"\n",
    "                 --scale_values=\"[58.395, 57.12 , 57.375]\"\n",
    "                 --data_type FP16\n",
    "                 --output_dir \"{model_path.parent}\"\n",
    "                 \"\"\"\n",
    "mo_command = \" \".join(mo_command.split())\n",
    "print(\"Model Optimizer command to convert the ONNX model to OpenVINO:\")\n",
    "display(Markdown(f\"`{mo_command}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d30a7",
   "metadata": {
    "id": "6YUwrq7QWSzw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not ir_path.exists():\n",
    "    print(\"Exporting ONNX model to IR... This may take a few minutes.\")\n",
    "    mo_result = %sx $mo_command\n",
    "    print(\"\\n\".join(mo_result))\n",
    "else:\n",
    "    print(f\"IR model {ir_path} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed2610",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Fastseg](https://github.com/ekzhang/fastseg)\n",
    "* [PIP install openvino-dev](https://github.com/openvinotoolkit/openvino/blob/releases/2021/3/docs/install_guides/pypi-openvino-dev.md)\n",
    "* [OpenVINO ONNX support](https://docs.openvino.ai/2021.4/openvino_docs_IE_DG_ONNX_Support.html)\n",
    "* [Model Optimizer Documentation](https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae617ccb002f72b3ab6d0069d721eac67ac2a969e83c083c4321cfcab0437cd1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
