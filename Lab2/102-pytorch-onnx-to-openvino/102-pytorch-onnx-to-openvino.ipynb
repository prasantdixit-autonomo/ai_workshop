{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af86d01b",
   "metadata": {
    "id": "JwEAhQVzkAwA"
   },
   "source": [
    "# Convert a PyTorch Model to ONNX and OpenVINO IR\n",
    "\n",
    "This tutorial demonstrates step-by-step instructions to convert the PyTorch model to [ONNX](https://onnx.ai/) and OpenVINO Intermediate Representation (IR) formats. The model is pre-trained on the [CityScapes](https://www.cityscapes-dataset.com) dataset. The source of the model is [FastSeg](https://github.com/ekzhang/fastseg)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf8008",
   "metadata": {
    "id": "QB4Yo-rGGLmV"
   },
   "source": [
    "## Preparation\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2573d828",
   "metadata": {
    "id": "2ynWRum4iiTz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intel/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/intel/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Markdown, display\n",
    "from fastseg import MobileV3Large\n",
    "from openvino.runtime import Core\n",
    "\n",
    "sys.path.append(\"utils\")\n",
    "from notebook_utils import CityScapesSegmentation, segmentation_map_to_image, viz_result_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b80fe4",
   "metadata": {},
   "source": [
    "### Settings\n",
    "\n",
    "Set the name for the model, and the image width and height that will be used for the network. CityScapes is pretrained on images of 2048x1024. Using smaller dimensions will impact model accuracy, but will improve inference speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a9303a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 1024  # Suggested values: 2048, 1024 or 512. The minimum width is 512.\n",
    "# Set IMAGE_HEIGHT manually for custom input sizes. Minimum height is 512\n",
    "IMAGE_HEIGHT = 1024 if IMAGE_WIDTH == 2048 else 512\n",
    "DIRECTORY_NAME = \"model\"\n",
    "BASE_MODEL_NAME = DIRECTORY_NAME + f\"/fastseg{IMAGE_WIDTH}\"\n",
    "\n",
    "# Paths where PyTorch, ONNX and OpenVINO IR models will be stored\n",
    "model_path = Path(BASE_MODEL_NAME).with_suffix(\".pth\")\n",
    "onnx_path = model_path.with_suffix(\".onnx\")\n",
    "ir_path = model_path.with_suffix(\".xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b33033e",
   "metadata": {
    "id": "u5xKw0hR0jq6"
   },
   "source": [
    "### Download the Fastseg Model\n",
    "\n",
    "Download, load and save the model with pretrained weights. This may take some time if you have not downloaded the model before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9600481",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGKkMRfvi0op",
    "outputId": "4eb1f9af-a4c5-424c-f808-dd9cc2600975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the Fastseg model (if it has not been downloaded before)....\n",
      "Loading pretrained model mobilev3large-lraspp with F=128...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ekzhang/fastseg/releases/download/v0.1-weights/mobilev3large-lraspp-f128-9cbabfde.pt\" to /home/intel/.cache/torch/checkpoints/mobilev3large-lraspp-f128-9cbabfde.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17292f029be34e47a23326b97cb5051a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/25.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mobilenetv3_large_100-427764d5.pth\" to /home/intel/.cache/torch/checkpoints/tf_mobilenetv3_large_100-427764d5.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PyTorch Fastseg model\n",
      "Model saved at model/fastseg1024.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading the Fastseg model (if it has not been downloaded before)....\")\n",
    "model = MobileV3Large.from_pretrained().cpu().eval()\n",
    "print(\"Loaded PyTorch Fastseg model\")\n",
    "\n",
    "# Save the model\n",
    "model_path.parent.mkdir(exist_ok=True)\n",
    "torch.save(model.state_dict(), str(model_path))\n",
    "print(f\"Model saved at {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad92bb9",
   "metadata": {
    "id": "Rhc_7EObUypw"
   },
   "source": [
    "## ONNX Model Conversion\n",
    "\n",
    "### Convert PyTorch model to ONNX\n",
    "\n",
    "The output for this cell will show some warnings. These are most likely harmless. Conversion succeeded if the last line of the output says `ONNX model exported to fastseg1024.onnx.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659aeac7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipQWpbgQUxoo",
    "outputId": "bbc1734a-c2a2-4261-ed45-264b9e3edd00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
      "/home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:39: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
      "/home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:39: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
      "/home/intel/.local/lib/python3.8/site-packages/geffnet/conv2d_layers.py:63: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/home/intel/.local/lib/python3.8/site-packages/torch/onnx/utils.py:613: DeprecationWarning: an integer is required (got type torch._C._onnx.TensorProtoDataType).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  return getattr(node, kind + \"_\")(name, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model exported to model/fastseg1024.onnx.\n"
     ]
    }
   ],
   "source": [
    "if not onnx_path.exists():\n",
    "    dummy_input = torch.randn(1, 3, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "\n",
    "    # For the Fastseg model, setting do_constant_folding to False is required\n",
    "    # for PyTorch>1.5.1\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=False,\n",
    "    )\n",
    "    print(f\"ONNX model exported to {onnx_path}.\")\n",
    "else:\n",
    "    print(f\"ONNX model {onnx_path} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490241b",
   "metadata": {
    "id": "6JSoEIk60uxV"
   },
   "source": [
    "### Convert ONNX Model to OpenVINO IR Format\n",
    "\n",
    "Call the OpenVINO Model Optimizer tool to convert the ONNX model to OpenVINO IR with FP16 precision. The models are saved to the current directory. We add the mean values to the model and scale the output with the standard deviation with `--scale_values`. With these options, it is not necessary to normalize input data before propagating it through the network.\n",
    "\n",
    "See the [Model Optimizer Developer Guide](https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html) for more information about Model Optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99ea10",
   "metadata": {},
   "source": [
    "Executing this command may take a while. There may be some errors or warnings in the output. Model Optimization was successful if the last lines of the output include `[ SUCCESS ] Generated IR version 11 model.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1e8029",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer command to convert the ONNX model to OpenVINO:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "`mo --input_model \"model/fastseg1024.onnx\" --input_shape \"[1,3, 512, 1024]\" --mean_values=\"[123.675, 116.28 , 103.53]\" --scale_values=\"[58.395, 57.12 , 57.375]\" --data_type FP16 --output_dir \"model\"`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct the command for Model Optimizer\n",
    "mo_command = f\"\"\"mo\n",
    "                 --input_model \"{onnx_path}\"\n",
    "                 --input_shape \"[1,3, {IMAGE_HEIGHT}, {IMAGE_WIDTH}]\"\n",
    "                 --mean_values=\"[123.675, 116.28 , 103.53]\"\n",
    "                 --scale_values=\"[58.395, 57.12 , 57.375]\"\n",
    "                 --data_type FP16\n",
    "                 --output_dir \"{model_path.parent}\"\n",
    "                 \"\"\"\n",
    "mo_command = \" \".join(mo_command.split())\n",
    "print(\"Model Optimizer command to convert the ONNX model to OpenVINO:\")\n",
    "display(Markdown(f\"`{mo_command}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e48d30a7",
   "metadata": {
    "id": "6YUwrq7QWSzw",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting ONNX model to IR... This may take a few minutes.\n",
      "/home/intel/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/intel/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/intel/JK/config_ai/ai_workshop/Lab2/102-pytorch-onnx-to-openvino/model/fastseg1024.onnx\n",
      "\t- Path for generated IR: \t/home/intel/JK/config_ai/ai_workshop/Lab2/102-pytorch-onnx-to-openvino/model\n",
      "\t- IR output name: \tfastseg1024\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,3, 512, 1024]\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \t[123.675, 116.28 , 103.53]\n",
      "\t- Scale values: \t[58.395, 57.12 , 57.375]\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "/home/intel/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/intel/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "OpenVINO runtime found in: \t/home/intel/.local/lib/python3.8/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-7019-cdb9bec7210-releases/2022/1\n",
      "Model Optimizer version: \t2022.1.0-7019-cdb9bec7210-releases/2022/1\n",
      "/home/intel/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/intel/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/intel/JK/config_ai/ai_workshop/Lab2/102-pytorch-onnx-to-openvino/model/fastseg1024.xml\n",
      "[ SUCCESS ] BIN file: /home/intel/JK/config_ai/ai_workshop/Lab2/102-pytorch-onnx-to-openvino/model/fastseg1024.bin\n",
      "[ SUCCESS ] Total execution time: 0.63 seconds. \n",
      "[ SUCCESS ] Memory consumed: 117 MB. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai\n"
     ]
    }
   ],
   "source": [
    "if not ir_path.exists():\n",
    "    print(\"Exporting ONNX model to IR... This may take a few minutes.\")\n",
    "    mo_result = %sx $mo_command\n",
    "    print(\"\\n\".join(mo_result))\n",
    "else:\n",
    "    print(f\"IR model {ir_path} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed2610",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Fastseg](https://github.com/ekzhang/fastseg)\n",
    "* [PIP install openvino-dev](https://github.com/openvinotoolkit/openvino/blob/releases/2021/3/docs/install_guides/pypi-openvino-dev.md)\n",
    "* [OpenVINO ONNX support](https://docs.openvino.ai/2021.4/openvino_docs_IE_DG_ONNX_Support.html)\n",
    "* [Model Optimizer Documentation](https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae617ccb002f72b3ab6d0069d721eac67ac2a969e83c083c4321cfcab0437cd1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
